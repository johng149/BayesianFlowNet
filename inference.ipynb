{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc806b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.generate import generative_prior, bayesian_inference, inference\n",
    "from src.inference.conditional import half_callback_maker\n",
    "import torch\n",
    "from src.common.data_prep import dis_t\n",
    "from src.datasets.dataset_helper import make_collate_fn\n",
    "from src.datasets.shakespeare.shakespeare import ShakespeareDataset as Ds\n",
    "# from src.datasets.synth.synthetic import DiscreteSyntheticDataset as Ds\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a687a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67363796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn.discrete_model import DiscreteModel as Model\n",
    "from src.tokenizers.character_level.character_level import CharacterLevelTokenizer as Tk\n",
    "from src.schedule.vanilla import VanillaScheduler as Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b80308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.checkpointing.checkpointing import load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea08fbf",
   "metadata": {},
   "source": [
    "### BFN Solver from Unifying BFN with Diffusion Models paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c57e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextBFNSolver:\n",
    "    def __init__(self, unet: torch.nn.Module, class_num: int = 27,\n",
    "                 num_steps: int = 100, max_sqrt_beta: float = 0.75, eta: float = 1e-5, callback=None):\n",
    "        self.unet = unet\n",
    "        self.eta = eta\n",
    "        self.callback = callback\n",
    "        \n",
    "        self.max_sqrt_beta = max_sqrt_beta\n",
    "        self.K = class_num\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.steps = torch.flip(torch.arange(num_steps+1), [0])\n",
    "        self.times = self.steps.to(torch.float64) / num_steps *  (1 - eta)\n",
    "        self.delta_t = (1 - eta) / num_steps\n",
    "        \n",
    "        \n",
    "        # f g\n",
    "        self.f_t = -2 / (1 - self.times)\n",
    "        self.g_t = (2 * self.K * (1 - self.times))**0.5 * self.max_sqrt_beta\n",
    "\n",
    "        # beta alpha\n",
    "        self.beta_t  = (self.max_sqrt_beta * (1 - self.times))**2\n",
    "        self.alpha_t = 2 * (1 - self.times) * self.max_sqrt_beta**2\n",
    "\n",
    "    \n",
    "    def sde_euler_update(self, x_s, step, mask, model_input, last_drop=False, cate_samp=False, addi_step=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "\n",
    "        g = self.g_t[step]\n",
    "\n",
    "        noise = torch.randn_like(x_s, device=x_s.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                categorical = TorchCategorical(logits=logits, validate_args=False)\n",
    "                data_pred = categorical.sample()\n",
    "                data_pred = F.one_hot(data_pred.long(), self.K)\n",
    "\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred    \n",
    "            elif addi_step == True and step == self.num_steps - 1:\n",
    "                x_t = x_s + g**2 * (data_pred - 1/self.K) * self.delta_t + g * self.delta_t**0.5 * noise\n",
    "                theta = F.softmax(x_t, -1)\n",
    "                t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step+1])\n",
    "                theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "                logits = self.unet(theta, t, mask)\n",
    "                data_pred = F.softmax(logits, -1)\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = x_s + g**2 * (data_pred - 1/self.K) * self.delta_t + g * self.delta_t**0.5 * noise\n",
    "                return logits, data_pred\n",
    "\n",
    "    def ode_euler_update(self, x_s, step, mask, model_input, last_drop=False, cate_samp=False, addi_step=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "\n",
    "        f = self.f_t[step]\n",
    "        g = self.g_t[step]\n",
    "        beta_s = self.beta_t[step]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                categorical = TorchCategorical(logits=logits, validate_args=False)\n",
    "                data_pred = categorical.sample()\n",
    "                data_pred = F.one_hot(data_pred.long(), self.K)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            elif addi_step == True and step == self.num_steps - 1:\n",
    "                x_t = x_s - ((f + (g**2)/(2 * self.K * beta_s)) * x_s - 0.5 * g**2 *(data_pred -1/self.K)) * self.delta_t\n",
    "                theta = F.softmax(x_t, -1)\n",
    "                t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step+1])\n",
    "                theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "                logits = self.unet(theta, t, mask)\n",
    "                data_pred = F.softmax(logits, -1)\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = x_s - ((f + (g**2)/(2 * self.K * beta_s)) * x_s - 0.5 * g**2 *(data_pred -1/self.K)) * self.delta_t\n",
    "                return x_t, data_pred\n",
    "\n",
    "    def ode_bfnsolver1_update(self, x_s, step, mask, model_input, last_drop=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = (1-t_t)/(1-t_s) * x_s +c_t * (t_t -t_s) * ( 1 / self.K - data_pred)\n",
    "                return x_t, data_pred\n",
    "    \n",
    "    def ode_bfnsolver2_multi_step_update(self, x_s, step, mask, model_input, data_pred_last=None, last_drop=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if step == 0:\n",
    "                x_t = (1 - t_t) / (1 - t_s) * x_s + c_t * (t_t - t_s) * (1 / self.K - data_pred) \n",
    "                return x_t, data_pred\n",
    "            elif last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                t_r = self.times[step - 1]\n",
    "                # x_t = x_s + \n",
    "                A = (1 - t_t) / (1 - t_s) * x_s + c_t / self.K * (t_t - t_s)\n",
    "                B = -c_t * (t_t - t_s) * data_pred\n",
    "                D1 = (data_pred - data_pred_last)/(t_s - t_r)\n",
    "                C = -c_t * (t_t - t_s)**2 / 2 * D1\n",
    "                x_t = A + B + C\n",
    "                return A + B + C, data_pred\n",
    "\n",
    "    def ode_bfnsolver2_single_step_update(self, x_s, step, mask, model_input, last_drop=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        t_r = (t_t + t_s)/2\n",
    "        c_r = self.K * self.max_sqrt_beta**2 * (1 - t_r)\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred_s = F.softmax(logits, -1)\n",
    "        \n",
    "            # x_r\n",
    "            x_r = (1 - t_r)/(1 - t_s) * x_s + c_r * (t_r - t_s) * (1 / self.K - data_pred_s)\n",
    "            t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - t_r)\n",
    "            theta = F.softmax(x_r, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            data_pred_r = F.softmax(logits, -1)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred_r\n",
    "            else:\n",
    "                A = (1 - t_t)/ (1 - t_s) * x_s + c_t / self.K * (t_t - t_s)\n",
    "                B = -c_t * (t_t - t_s) * data_pred_s\n",
    "                D1 = (data_pred_r - data_pred_s)/(t_r - t_s)\n",
    "                C = -c_t * (t_t - t_s)**2 / 2 * D1\n",
    "                x_t = A + B + C\n",
    "                return x_t, data_pred_r\n",
    "    \n",
    "    def sde_bfnsolver2_multi_step_update(self, x_s, step, mask, model_input, data_pred_last=None, last_drop=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        beta_s = self.max_sqrt_beta**2 * (1 - t_s)**2\n",
    "        beta_t = self.max_sqrt_beta**2 * (1 - t_t)**2\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred_s = F.softmax(logits, -1)\n",
    "            if step == 0:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1)  + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred_s\n",
    "            elif last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred_s\n",
    "            else:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                t_r = self.times[step-1]\n",
    "                D1 = (data_pred_last - data_pred_s)/(t_r - t_s)\n",
    "                # x_t_ = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1)\\\n",
    "                #     + (2*self.K*self.max_sqrt_beta**2*( ((t_t**2)/2 - (t_t**3)/3) - ((t_s**2)/2-(t_s**3)/3 ) ) + t_s * self.K * (beta_t - beta_s)) * D1 \\\n",
    "                #         + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1) \\\n",
    "                    + 1/3 * self.K * self.max_sqrt_beta**2 * (t_t - t_s)**2 * (t_s + 2 * t_t -3) * D1 \\\n",
    "                    + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred_s\n",
    "\n",
    "    def sde_bfnsolver1_update(self, x_s, step, mask, model_input, last_drop=False, cate_samp=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        beta_s = self.max_sqrt_beta**2 * (1 - t_s)**2\n",
    "        beta_t = self.max_sqrt_beta**2 * (1 - t_t)**2\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            theta = torch.where(mask.unsqueeze(-1), theta, model_input)\n",
    "            logits = self.unet(theta, t, mask)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                data_pred = TorchCategorical(logits=logits, validate_args=False).sample()\n",
    "                data_pred = F.one_hot(data_pred, self.K).to(torch.float32)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred - 1)  + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d4f1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(solver: TextBFNSolver, batch_size, seq_len, K, mask, model_input, device, steps: int = 100, algorithm: str = \"sde_euler\"):\n",
    "    beta_t = (solver.max_sqrt_beta * solver.eta) ** 2\n",
    "    std_t = (K * beta_t) ** 0.5\n",
    "    prior = torch.randn(batch_size, seq_len, K, device=device) * std_t\n",
    "    xt = prior\n",
    "    data_pred_last = None\n",
    "    for step in tqdm(range(steps)):\n",
    "        if algorithm == \"sde_euler\":\n",
    "            xt, _ = solver.sde_euler_update(xt, step, mask, model_input)\n",
    "        elif algorithm == \"ode_euler\":\n",
    "            xt, _ = solver.ode_euler_update(xt, step, mask, model_input)\n",
    "        elif algorithm == \"ode_bfnsolver1\":\n",
    "            xt, _ = solver.ode_bfnsolver1_update(xt, step, mask, model_input)\n",
    "        elif algorithm == \"ode_bfnsolver2_single_step\":\n",
    "            xt, _ = solver.ode_bfnsolver2_single_step_update(xt, step, mask, model_input)\n",
    "        elif algorithm == \"ode_bfnsolver2_multi_step\":\n",
    "            xt, data_pred_last = solver.ode_bfnsolver2_multi_step_update(xt, step, mask, model_input, data_pred_last)\n",
    "        elif algorithm == \"sde_bfnsolver1\":\n",
    "            xt, _ = solver.sde_bfnsolver1_update(xt, step, mask, model_input)\n",
    "        elif algorithm == \"sde_bfnsolver2_multi_step\":\n",
    "            xt, data_pred_last = solver.sde_bfnsolver2_multi_step_update(xt, step, mask, model_input, data_pred_last)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1905d1d",
   "metadata": {},
   "source": [
    "### Generation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c05126ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(log_with=\"tensorboard\", project_dir=\"./runs\")\n",
    "checkpoint_name = \"model_conditional\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "batch_size = 256\n",
    "seq_len = 128\n",
    "min_t = 1e-8\n",
    "num_workers = 3\n",
    "hidden_size = 768\n",
    "layers = 6\n",
    "heads = 12\n",
    "tk = Tk()\n",
    "vocab_size = tk.vocab_size()\n",
    "scheduler = Scheduler(20.4054 / vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6299eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    max_seq_len=seq_len,\n",
    "    K=vocab_size,\n",
    "    hidden_dim=hidden_size,\n",
    "    num_heads=heads,\n",
    "    layers=layers,\n",
    "    dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff52bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, _ = load_checkpoint(model, None, None, accelerator, checkpoint_dir + f\"/{checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5ec98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for karpathy/tiny_shakespeare contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/karpathy/tiny_shakespeare\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = Ds(tk, seq_len, min_t=min_t, train=True)\n",
    "\n",
    "collate_fn = make_collate_fn(scheduler, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e36e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "869147b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8876350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ground_truth['ground_truth'].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "668bd427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"e consider'd in my mind<UNK>the late demand that you did sound me in.<UNK><UNK>king richard iii:<UNK>well, let that pass. dorset is fled to rich\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.decode(gt[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a29d3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ground_truth['mask'].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7396ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True, False,  True,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "          True, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True, False,  True, False, False, False, False, False,\n",
       "         False, False, False,  True, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "         False,  True,  True,  True,  True, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8b8ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = ground_truth['model_input'].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee04d518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"uieok<UNK>ider'd in m'x:rnd<UNK>theqyzre'ddmand thak you did so? dh efqa?<UNK><UNK>king richard oxomdwjfe, let that pass. dorset is fled to rich\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.decode(torch.argmax(model_input[0], dim=-1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7ba971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128]), torch.Size([1, 128, 35]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape, model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd3eb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: o'zolaider'd in qs;x?nd<UNK>thesz.ifxd'mand thaw you did soljrbyele!!<UNK><UNK>king richard wkofawaml, let that pass. dorset is fled to rich\n",
      "Step 20: h fon!ider'd in cf gfnd<UNK>thex: :fbdsmand thah you did soxyr leob!!<UNK><UNK>king richard f,mc<UNK>wynr, let that pass. dorset is fled to rich\n",
      "Step 30: jpuon!ider'd in uy j?nd<UNK>thepgekfmdlmand thay you did soxkrmlea,sc<UNK><UNK>king richard fmoz<UNK>wel!, let that pass. dorset is fled to rich\n",
      "Step 40: k konuider'd in mh mhnd<UNK>the seuf djmand tha? you did soxbrrle;,yr<UNK><UNK>king richard imioxweqr, let that pass. dorset is fled to rich\n",
      "Step 50: v uon.ider'd in mycm nd<UNK>the geuf dlmand thap you did soxbrroe;t,r<UNK><UNK>king richard i?ioywely, let that pass. dorset is fled to rich\n",
      "Step 60: c cohsider'd in my mind<UNK>the geuf d,mand thap you did soexcrme;;,.<UNK><UNK>king richard i?io<UNK>welq, let that pass. dorset is fled to rich\n",
      "Step 70: h consider'd in my mind<UNK>the ge:f demand thap you did so ec,me eu.<UNK><UNK>king richard iii:<UNK>welq, let that pass. dorset is fled to rich\n",
      "Step 80: h consider'd in my<UNK>mind<UNK>the self demand that you did soeec me bu.<UNK><UNK>king richard iiio<UNK>welq, let that pass. dorset is fled to rich\n",
      "Step 90: h consider'd in my mind<UNK>the self demand that you did soee  me b,.<UNK><UNK>king richard iii:<UNK>welq, let that pass. dorset is fled to rich\n",
      "Step 100: h consider'd in my mind<UNK>the self demand that you did soee  me b<UNK>.<UNK><UNK>king richard iii:<UNK>well, let that pass. dorset is fled to rich\n"
     ]
    }
   ],
   "source": [
    "output = inference(model, scheduler, 100, 1, gt.shape[1], tk.vocab_size(), mask, model_input, accelerator.device, torch.float, None, tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a5aa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = output.argmax(dim=-1) == gt.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b83d67c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714285850524902"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match[mask].float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c0d2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_solver = TextBFNSolver(model, class_num=tk.vocab_size(), num_steps=100, max_sqrt_beta=(20.4054 / vocab_size)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "395a5ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9ab3bb38f0475b894d88c6761d9ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e consider'd in my mind<UNK>the king demand that you did so leave it.<UNK><UNK>king richard iii:<UNK>well, let that pass. dorset is fled to rich\n"
     ]
    }
   ],
   "source": [
    "xt = sample(\n",
    "    text_solver,\n",
    "    1,\n",
    "    gt.shape[1],\n",
    "    tk.vocab_size(),\n",
    "    mask,\n",
    "    model_input,\n",
    "    accelerator.device,\n",
    "    steps=100,\n",
    "    algorithm=\"sde_euler\",\n",
    ")\n",
    "cat = Categorical(logits=xt)\n",
    "mode = cat.mode\n",
    "generated_text = tk.decode(mode[0].cpu())\n",
    "print(f\"{generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffee60",
   "metadata": {},
   "source": [
    "### BFN Solver from Unifying BFN with Diffusion Models paper result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68a04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_euler\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcc768a65cf49799d11110f29886829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8320f4addf4d779f12b7f7cb313a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4458bdd71e504eaf819ed91d6ed24b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020b92665e11437ba1de5500cd8e0301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e4bbfea2d647fdb379397db9fd5b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_euler\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1552ff680cf1422e9b5cda2847f23f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d97856c6384dda813d3417b240f9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8446586de8444498e0dfdf8ca46523a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17752f28d454e8a975fbbb4d1fbe5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2780d6a74054b03967f28d7d850ce4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver1\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28a6284a00d4ecfa998125258d31af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a33582ad38d44f6851120be8f1bccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659a4632a8e34f9fb8ab0fecdbeff9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dd620029ce40b2b333aaa5e1fc14fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a5907a7c3e42b593a214280948b777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver2_single_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56231c521feb463684fb872b4d9be73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70af4def235b44b8bbf3b9a267f9d5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54775610dc464775b8796cf568fd948d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e226ea454ac84de79e06f9f679c5d958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fddbff9eaa14a6b9369317f95d05ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver2_multi_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb6b4ac1c6a478bafc2e91944b88000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629cc7bc046a45bd8f0987838ae7e9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e7905c951444158c20844e6d4ea769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d88acdb33124800895ec7008846b558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe12603c8f0487f93499d70e20fd360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_bfnsolver1\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac663df92e2445af8c4b294740049ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab256e776b24becb6d59716d98e0152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88921e799164fb4bee9f2102e6fa043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f96593e584f471a8a87d4fe393944c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b42e3f80a744071b6e7eb2e6f4c651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_bfnsolver2_multi_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbbb4b5f92a44019584411dd695f179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0165a18ff7cb4870a463643452d772f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91f8eaac3694125b52448f528423c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27a76d9797b4507a526608fe6a4677a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efe5eeae0604098886d79c6d2a60376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to solver_results.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "algorithms = [\n",
    "    \"sde_euler\",\n",
    "    \"ode_euler\",\n",
    "    \"ode_bfnsolver1\",\n",
    "    \"ode_bfnsolver2_single_step\",\n",
    "    \"ode_bfnsolver2_multi_step\",\n",
    "    \"sde_bfnsolver1\",\n",
    "    \"sde_bfnsolver2_multi_step\",\n",
    "]\n",
    "num_samples_per_algorithm = 5\n",
    "results_file = \"solver_results.txt\"\n",
    "\n",
    "with open(results_file, \"w\") as f:\n",
    "    for algorithm in algorithms:\n",
    "        f.write(f\"--- Algorithm: {algorithm} ---\\n\")\n",
    "        print(f\"Running algorithm: {algorithm}\")\n",
    "        for i in range(num_samples_per_algorithm):\n",
    "            print(f\"  Sample {i+1}/{num_samples_per_algorithm}\")\n",
    "            xt = sample(\n",
    "                text_solver,\n",
    "                1,\n",
    "                gt.shape[1],\n",
    "                tk.vocab_size(),\n",
    "                accelerator.device,\n",
    "                steps=100,\n",
    "                algorithm=algorithm,\n",
    "            )\n",
    "            cat = Categorical(logits=xt)\n",
    "            mode = cat.mode\n",
    "            generated_text = tk.decode(mode[0].cpu())\n",
    "            f.write(f\"Sample {i+1}: {generated_text}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50239d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
