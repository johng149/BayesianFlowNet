{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bc806b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.generate import generative_prior, bayesian_inference, inference\n",
    "from src.inference.conditional import half_callback_maker\n",
    "import torch\n",
    "from src.common.data_prep import dis_t\n",
    "from src.datasets.dataset_helper import make_collate_fn\n",
    "from src.datasets.shakespeare.shakespeare import ShakespeareDataset as Ds\n",
    "# from src.datasets.synth.synthetic import DiscreteSyntheticDataset as Ds\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a687a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67363796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn.discrete_model import DiscreteModel as Model\n",
    "from src.tokenizers.character_level.character_level import CharacterLevelTokenizer as Tk\n",
    "from src.schedule.vanilla import VanillaScheduler as Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92b80308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.checkpointing.checkpointing import load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea08fbf",
   "metadata": {},
   "source": [
    "### BFN Solver from Unifying BFN with Diffusion Models paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82c57e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextBFNSolver:\n",
    "    def __init__(self, unet: torch.nn.Module, class_num: int = 27,\n",
    "                 num_steps: int = 100, max_sqrt_beta: float = 0.75, eta: float = 1e-5, callback=None):\n",
    "        self.unet = unet\n",
    "        self.eta = eta\n",
    "        self.callback = callback\n",
    "        \n",
    "        self.max_sqrt_beta = max_sqrt_beta\n",
    "        self.K = class_num\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.steps = torch.flip(torch.arange(num_steps+1), [0])\n",
    "        self.times = self.steps.to(torch.float64) / num_steps *  (1 - eta)\n",
    "        self.delta_t = (1 - eta) / num_steps\n",
    "        \n",
    "        \n",
    "        # f g\n",
    "        self.f_t = -2 / (1 - self.times)\n",
    "        self.g_t = (2 * self.K * (1 - self.times))**0.5 * self.max_sqrt_beta\n",
    "\n",
    "        # beta alpha\n",
    "        self.beta_t  = (self.max_sqrt_beta * (1 - self.times))**2\n",
    "        self.alpha_t = 2 * (1 - self.times) * self.max_sqrt_beta**2\n",
    "\n",
    "    \n",
    "    def sde_euler_update(self, x_s, step, encoder_input, last_drop=False, cate_samp=False, addi_step=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "\n",
    "        g = self.g_t[step]\n",
    "\n",
    "        noise = torch.randn_like(x_s, device=x_s.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                categorical = TorchCategorical(logits=logits, validate_args=False)\n",
    "                data_pred = categorical.sample()\n",
    "                data_pred = F.one_hot(data_pred.long(), self.K)\n",
    "\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred    \n",
    "            elif addi_step == True and step == self.num_steps - 1:\n",
    "                x_t = x_s + g**2 * (data_pred - 1/self.K) * self.delta_t + g * self.delta_t**0.5 * noise\n",
    "                theta = F.softmax(x_t, -1)\n",
    "                t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step+1])\n",
    "                logits = self.unet(theta, t, encoder_input)\n",
    "                data_pred = F.softmax(logits, -1)\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = x_s + g**2 * (data_pred - 1/self.K) * self.delta_t + g * self.delta_t**0.5 * noise\n",
    "                return logits, data_pred\n",
    "\n",
    "    def ode_euler_update(self, x_s, step, encoder_input, last_drop=False, cate_samp=False, addi_step=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "\n",
    "        f = self.f_t[step]\n",
    "        g = self.g_t[step]\n",
    "        beta_s = self.beta_t[step]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                categorical = TorchCategorical(logits=logits, validate_args=False)\n",
    "                data_pred = categorical.sample()\n",
    "                data_pred = F.one_hot(data_pred.long(), self.K)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            elif addi_step == True and step == self.num_steps - 1:\n",
    "                x_t = x_s - ((f + (g**2)/(2 * self.K * beta_s)) * x_s - 0.5 * g**2 *(data_pred -1/self.K)) * self.delta_t\n",
    "                theta = F.softmax(x_t, -1)\n",
    "                t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step+1])\n",
    "                logits = self.unet(theta, t, encoder_input)\n",
    "                data_pred = F.softmax(logits, -1)\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = x_s - ((f + (g**2)/(2 * self.K * beta_s)) * x_s - 0.5 * g**2 *(data_pred -1/self.K)) * self.delta_t\n",
    "                return x_t, data_pred\n",
    "\n",
    "    def ode_bfnsolver1_update(self, x_s, step, encoder_input, last_drop=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                x_t = (1-t_t)/(1-t_s) * x_s +c_t * (t_t -t_s) * ( 1 / self.K - data_pred)\n",
    "                return x_t, data_pred\n",
    "    \n",
    "    def ode_bfnsolver2_multi_step_update(self, x_s, step, encoder_input, data_pred_last=None, last_drop=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if step == 0:\n",
    "                x_t = (1 - t_t) / (1 - t_s) * x_s + c_t * (t_t - t_s) * (1 / self.K - data_pred) \n",
    "                return x_t, data_pred\n",
    "            elif last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                t_r = self.times[step - 1]\n",
    "                # x_t = x_s + \n",
    "                A = (1 - t_t) / (1 - t_s) * x_s + c_t / self.K * (t_t - t_s)\n",
    "                B = -c_t * (t_t - t_s) * data_pred\n",
    "                D1 = (data_pred - data_pred_last)/(t_s - t_r)\n",
    "                C = -c_t * (t_t - t_s)**2 / 2 * D1\n",
    "                x_t = A + B + C\n",
    "                return A + B + C, data_pred\n",
    "\n",
    "    def ode_bfnsolver2_single_step_update(self, x_s, step, encoder_input, last_drop=False):\n",
    "        # x_s -> x_t\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        t_r = (t_t + t_s)/2\n",
    "        c_r = self.K * self.max_sqrt_beta**2 * (1 - t_r)\n",
    "        c_t = self.K * self.max_sqrt_beta**2 * (1 - t_t)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred_s = F.softmax(logits, -1)\n",
    "        \n",
    "            # x_r\n",
    "            x_r = (1 - t_r)/(1 - t_s) * x_s + c_r * (t_r - t_s) * (1 / self.K - data_pred_s)\n",
    "            t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - t_r)\n",
    "            theta = F.softmax(x_r, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            data_pred_r = F.softmax(logits, -1)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred_r\n",
    "            else:\n",
    "                A = (1 - t_t)/ (1 - t_s) * x_s + c_t / self.K * (t_t - t_s)\n",
    "                B = -c_t * (t_t - t_s) * data_pred_s\n",
    "                D1 = (data_pred_r - data_pred_s)/(t_r - t_s)\n",
    "                C = -c_t * (t_t - t_s)**2 / 2 * D1\n",
    "                x_t = A + B + C\n",
    "                return x_t, data_pred_r\n",
    "    \n",
    "    def sde_bfnsolver2_multi_step_update(self, x_s, step, encoder_input, data_pred_last=None, last_drop=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        beta_s = self.max_sqrt_beta**2 * (1 - t_s)**2\n",
    "        beta_t = self.max_sqrt_beta**2 * (1 - t_t)**2\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred_s = F.softmax(logits, -1)\n",
    "            if step == 0:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1)  + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred_s\n",
    "            elif last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred_s\n",
    "            else:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                t_r = self.times[step-1]\n",
    "                D1 = (data_pred_last - data_pred_s)/(t_r - t_s)\n",
    "                # x_t_ = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1)\\\n",
    "                #     + (2*self.K*self.max_sqrt_beta**2*( ((t_t**2)/2 - (t_t**3)/3) - ((t_s**2)/2-(t_s**3)/3 ) ) + t_s * self.K * (beta_t - beta_s)) * D1 \\\n",
    "                #         + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred_s - 1) \\\n",
    "                    + 1/3 * self.K * self.max_sqrt_beta**2 * (t_t - t_s)**2 * (t_s + 2 * t_t -3) * D1 \\\n",
    "                    + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred_s\n",
    "\n",
    "    def sde_bfnsolver1_update(self, x_s, step, encoder_input, last_drop=False, cate_samp=False):\n",
    "        t = torch.ones(x_s.shape[0], device=x_s.device) * (1 - self.times[step])\n",
    "        t_t, t_s = self.times[step + 1], self.times[step]\n",
    "        beta_s = self.max_sqrt_beta**2 * (1 - t_s)**2\n",
    "        beta_t = self.max_sqrt_beta**2 * (1 - t_t)**2\n",
    "        with torch.no_grad():\n",
    "            theta = F.softmax(x_s, -1)\n",
    "            logits = self.unet(theta, t, encoder_input)\n",
    "            if self.callback is not None:\n",
    "                logits = self.callback(logits)\n",
    "            data_pred = F.softmax(logits, -1)\n",
    "            if cate_samp == True:\n",
    "                data_pred = TorchCategorical(logits=logits, validate_args=False).sample()\n",
    "                data_pred = F.one_hot(data_pred, self.K).to(torch.float32)\n",
    "            if last_drop == True and step == self.num_steps - 1:\n",
    "                return logits, data_pred\n",
    "            else:\n",
    "                noise = torch.randn_like(x_s, device=x_s.device)\n",
    "                x_t = x_s + (beta_t - beta_s) * (self.K * data_pred - 1)  + (self.K * (beta_t - beta_s))**0.5 * noise\n",
    "                return x_t, data_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d4f1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(solver: TextBFNSolver, batch_size, seq_len, K, encoder_input, device, steps: int = 100, algorithm: str = \"sde_euler\"):\n",
    "    beta_t = (solver.max_sqrt_beta * solver.eta) ** 2\n",
    "    std_t = (K * beta_t) ** 0.5\n",
    "    prior = torch.randn(batch_size, seq_len, K, device=device) * std_t\n",
    "    xt = prior\n",
    "    data_pred_last = None\n",
    "    for step in tqdm(range(steps)):\n",
    "        if algorithm == \"sde_euler\":\n",
    "            xt, _ = solver.sde_euler_update(xt, step, encoder_input)\n",
    "        elif algorithm == \"ode_euler\":\n",
    "            xt, _ = solver.ode_euler_update(xt, step, encoder_input)\n",
    "        elif algorithm == \"ode_bfnsolver1\":\n",
    "            xt, _ = solver.ode_bfnsolver1_update(xt, step, encoder_input)\n",
    "        elif algorithm == \"ode_bfnsolver2_single_step\":\n",
    "            xt, _ = solver.ode_bfnsolver2_single_step_update(xt, step, encoder_input)\n",
    "        elif algorithm == \"ode_bfnsolver2_multi_step\":\n",
    "            xt, data_pred_last = solver.ode_bfnsolver2_multi_step_update(xt, step, encoder_input, data_pred_last)\n",
    "        elif algorithm == \"sde_bfnsolver1\":\n",
    "            xt, _ = solver.sde_bfnsolver1_update(xt, step, encoder_input)\n",
    "        elif algorithm == \"sde_bfnsolver2_multi_step\":\n",
    "            xt, data_pred_last = solver.sde_bfnsolver2_multi_step_update(xt, step, encoder_input, data_pred_last)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1905d1d",
   "metadata": {},
   "source": [
    "### Generation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05126ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(log_with=\"tensorboard\", project_dir=\"./runs\")\n",
    "checkpoint_name = \"conditional_shakespeare\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "batch_size = 256\n",
    "seq_len = 128\n",
    "min_t = 1e-8\n",
    "num_workers = 3\n",
    "hidden_size = 768\n",
    "layers = 6\n",
    "heads = 12\n",
    "tk = Tk()\n",
    "vocab_size = tk.vocab_size()\n",
    "scheduler = Scheduler(20.4054 / vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6299eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    dec_max_seq_len=seq_len,\n",
    "    enc_max_seq_len=seq_len,\n",
    "    K=vocab_size,\n",
    "    hidden_dim=hidden_size,\n",
    "    num_heads=heads,\n",
    "    decoder_layers=layers,\n",
    "    dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff52bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, _ = load_checkpoint(model, None, None, accelerator, checkpoint_dir + f\"/{checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ec98ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for karpathy/tiny_shakespeare contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/karpathy/tiny_shakespeare\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = Ds(tk, seq_len, min_t=min_t, train=True)\n",
    "\n",
    "collate_fn = make_collate_fn(scheduler, vocab_size, tk.mask_idx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e36e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "869147b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.dataset_helper import CollateOutput\n",
    "\n",
    "\n",
    "def pop_off_ground_truth(dl) -> CollateOutput:\n",
    "    ground_truth = next(iter(dl))\n",
    "    return ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3031e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pop_off_ground_truth(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8876350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ground_truth['ground_truth'].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "668bd427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' be endured:<UNK>what, goodman boy! i say, he shall: go to;<UNK>am i the'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.decode(gt[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18062766",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = ground_truth[\"encoder_model_input\"].to(accelerator.device)\n",
    "decoder_input = ground_truth[\"decoder_model_input\"].to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0860054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#half_callback, _ = half_callback_maker(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd3eb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/torch/nn/functional.py:6487: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:287.)\n",
      "  attn_output = scaled_dot_product_attention(\n",
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/torch/nn/functional.py:6487: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:338.)\n",
      "  attn_output = scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: u'ov:sg,ive:<UNK>cva,dkipgryodzb'kmg;u.n pcpx?ap;ny<UNK>vxoh emakhfm<UNK>hhf\n",
      "Step 20: g'o  zi;uqwi<UNK>m!nyhumsylbqola'khz!:wua.<UNK>yjtcei<UNK>qfwx;,e.?atgfm<UNK>has\n",
      "Step 30: :'ungzm;kqkimyvvtsiollkwk:bay! i :xqf.hyatsd;aqfwmzb .?adgam<UNK>fas\n",
      "Step 40: ;fu 'skeoe.:m.hvt,gmlmui  ba'z i :arza:uhbs;zaof: zf t?fsco!<UNK>fat\n",
      "Step 50:  pu tz!eoed:m.hrt,g:pdgj<UNK> ba:e i uabh tuhesdzaol: xd psflcoovfaa\n",
      "Step 60: bbe tznere.:<UNK>.hst,b:pdmjn bgge i uakcit hesjhaol: xo ;s l tolzat\n",
      "Step 70:  ce puneoed:'what,b,pdmin bvy! i rak f: hesshall: go ;o let leat\n",
      "Step 80:  be gunered:mwhat,goqdmbn boy! i rak,fe he shall: go ;o let!,zat\n",
      "Step 90:  be gunered:<UNK>what,g,ldmbn boy! i va  f, he shall: go to let le t\n",
      "Step 100:  be gunered:<UNK>what,goodmbn boy! i vay d, he shall: lo to let le t\n"
     ]
    }
   ],
   "source": [
    "output = inference(model, scheduler, 100, 1, decoder_input.shape[1], tk.vocab_size(), encoder_input, accelerator.device, torch.float, None, tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c0d2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_solver = TextBFNSolver(model, class_num=tk.vocab_size(), num_steps=300, max_sqrt_beta=(20.4054 / vocab_size)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f83ec67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe976a75fc147ac823352bf3e057c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " not add,au:<UNK>what, goodma boy ! i say, he shall. go too.<UNK>as i me\n"
     ]
    }
   ],
   "source": [
    "xt = sample(\n",
    "    text_solver,\n",
    "    1,\n",
    "    decoder_input.shape[1],\n",
    "    tk.vocab_size(),\n",
    "    encoder_input,\n",
    "    accelerator.device,\n",
    "    steps=300,\n",
    "    algorithm=\"sde_bfnsolver2_multi_step\"\n",
    ")\n",
    "cat = Categorical(logits=xt)\n",
    "mode = cat.mode\n",
    "generated_text = tk.decode(mode[0].cpu())\n",
    "print(f\"{generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffee60",
   "metadata": {},
   "source": [
    "### BFN Solver from Unifying BFN with Diffusion Models paper result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e68a04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_euler\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15482103abc14d3ba0b6a1f76f73d95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df0eed8a39643e6a223b12b382d8718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a31bf272c334251b86da05273ad6cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e68a6393d94c63ba0c04264320dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e41a59b13242edb12ef19b872ff80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_euler\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d363c74e89b4414396a815e2e73deeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6d08b0389c4664a295011fd3841e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3996a15e1d242e695504876c7fac000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f5c7a636de4a3da3017b0fa4fc2d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e9070d9c54e1a96e51b17712d8260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver1\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d585ec53d234b4397ad1cde08777507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc644a90a414592b93757959d4357b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e5411670724f4c90530c6952ef0f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0a05246ac7489cba2ebf188841d55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceab6bd4486e46ab8a71569aa74b780e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver2_single_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf1d0153aea450bb03ac70e25ac07ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f851475a251e4f34b6900de2cdf4c786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e3e2fc3f204618be7513d27e70b4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c15e7a89205463da70b1592e0117678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc5472fb3684c99a8f0081352a43b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: ode_bfnsolver2_multi_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b2c7c6654242b89242d94dc07ae913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f71225a9c6b49f79f2694684d49a29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37fe91356b4475792a566338620492f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da133b7f6c9844aba26399c6bb3561e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b002070aa75046eabb02a905edb3ce71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_bfnsolver1\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d09ff7355da483da08ba38e606ce04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bb76c169c847519dc4968622f0706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9326bd83c44941788e93e3f74b3f3d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8504ab4a9045a682201777482f210d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10798fd860504a929850cfc8c931e7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running algorithm: sde_bfnsolver2_multi_step\n",
      "  Sample 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab0f57eb2304dacb08255a7fdd06306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331e84bb369e452aaee4e56c8afeca7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87aadd40d7041a7bc3dbe02a25b3527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55c1ad550b545279aec38150c1da23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35aa3e646ad4ff4afce6b713d621724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to solver_results.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "algorithms = [\n",
    "    \"sde_euler\",\n",
    "    \"ode_euler\",\n",
    "    \"ode_bfnsolver1\",\n",
    "    \"ode_bfnsolver2_single_step\",\n",
    "    \"ode_bfnsolver2_multi_step\",\n",
    "    \"sde_bfnsolver1\",\n",
    "    \"sde_bfnsolver2_multi_step\",\n",
    "]\n",
    "num_samples_per_algorithm = 5\n",
    "results_file = \"solver_results.txt\"\n",
    "\n",
    "with open(results_file, \"w\") as f:\n",
    "    for algorithm in algorithms:\n",
    "        f.write(f\"--- Algorithm: {algorithm} ---\\n\")\n",
    "        print(f\"Running algorithm: {algorithm}\")\n",
    "        for i in range(num_samples_per_algorithm):\n",
    "            print(f\"  Sample {i+1}/{num_samples_per_algorithm}\")\n",
    "            xt = sample(\n",
    "                text_solver,\n",
    "                1,\n",
    "                gt.shape[1],\n",
    "                tk.vocab_size(),\n",
    "                encoder_input,\n",
    "                accelerator.device,\n",
    "                steps=300,\n",
    "                algorithm=algorithm,\n",
    "            )\n",
    "            cat = Categorical(logits=xt)\n",
    "            mode = cat.mode\n",
    "            generated_text = tk.decode(mode[0].cpu())\n",
    "            f.write(f\"Sample {i+1}: {generated_text}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50239d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
