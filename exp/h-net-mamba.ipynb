{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026ba8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mamba_ssm import Mamba2\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# need to be careful with setting d_model, headdim, and expand\n",
    "# packing had a ton of issues with casual conv1d when trying to use\n",
    "# arbitrary settings for these parameters.\n",
    "# what I know is that d_model = 64, headdim = 4, expand = 2 works\n",
    "# seems to suggest that https://github.com/state-spaces/mamba/issues/351\n",
    "# we need (d_model * expand) / headdim to be multiple of 8, that is\n",
    "# `(d_model * expand) / headdim % 8`\n",
    "batch, length, dim = 2, 16, 64\n",
    "expand = 2\n",
    "headdim = 4\n",
    "assert (dim * expand) % (headdim * 8) == 0, \"d_model * expand must be multiple of headdim * 8\"\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "model = Mamba2(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    headdim=4,\n",
    "    d_state=16,  # SSM state expansion factor\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    ")\n",
    "opt = AdamW(model.parameters(), lr=1e-3)\n",
    "model = model.to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70d9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = y.mean()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29749fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd79e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 comparison: True\n",
      "y2 comparison: True\n"
     ]
    }
   ],
   "source": [
    "# Let's test packed sequences\n",
    "# Create two tensors of different lengths\n",
    "s1 = 3\n",
    "s2 = 3\n",
    "x1 = torch.randn(1, s1, dim).to(\"cuda\")\n",
    "x2 = torch.randn(1, s2, dim).to(\"cuda\")\n",
    "\n",
    "seq_idx = [0] * s1 + [1] * s2\n",
    "seq_idx = torch.tensor(seq_idx, device=\"cuda\", dtype=torch.int32).unsqueeze(0)\n",
    "\n",
    "# Get individual outputs\n",
    "with torch.no_grad():\n",
    "    y1_individual = model(x1)\n",
    "    y2_individual = model(x2)\n",
    "\n",
    "# Create packed input\n",
    "x_packed = torch.cat([x1, x2], dim=1)\n",
    "x_packed.requires_grad_(True)\n",
    "cu_seqlens = torch.tensor([0, s1, s1 + s2], dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# Get packed output\n",
    "with torch.no_grad():\n",
    "    #y_packed = model(x_packed, seq_idx=seq_idx, cu_seqlens=cu_seqlens).squeeze(0)\n",
    "    y_packed = model(x_packed, seq_idx=seq_idx).squeeze(0)\n",
    "\n",
    "# Split packed output\n",
    "y1_packed = y_packed[:s1].unsqueeze(0)\n",
    "y2_packed = y_packed[s1:].unsqueeze(0)\n",
    "\n",
    "# Check if the outputs are the same\n",
    "print(\"y1 comparison:\", torch.allclose(y1_individual, y1_packed, atol=1e-6))\n",
    "print(\"y2 comparison:\", torch.allclose(y2_individual, y2_packed, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c167e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8275e-01, -2.8104e-01,  1.4621e-01, -7.5262e-01,  1.9000e-01,\n",
       "         -1.7658e-01, -5.2145e-01,  1.1147e+00,  3.3039e-01, -1.2642e-01,\n",
       "          9.4200e-01, -1.2819e-01, -2.8167e-01, -1.3622e-01, -1.8648e-01,\n",
       "          5.2313e-01,  8.3148e-01,  1.0460e+00, -6.3483e-02, -9.1206e-02,\n",
       "          2.0990e-01,  3.2346e-01, -3.1911e-02, -9.8545e-01, -5.8761e-01,\n",
       "          2.7666e-02,  6.9791e-01,  6.9201e-01,  1.8024e-01, -1.0535e-01,\n",
       "          8.5679e-01, -7.0666e-01,  1.1406e-01, -8.7556e-01,  8.9156e-01,\n",
       "          4.9201e-01, -3.5831e-01, -5.7950e-01, -7.3262e-02, -6.3449e-01,\n",
       "          3.9469e-01, -9.4976e-01, -4.6342e-01,  4.3465e-01,  1.9497e-01,\n",
       "         -8.4314e-01, -1.7105e-01,  1.1616e+00,  6.5661e-01, -9.2044e-01,\n",
       "          7.0604e-02, -3.5718e-01,  7.6152e-01,  8.1916e-01, -4.0435e-01,\n",
       "         -1.0596e+00, -5.9928e-01,  4.4862e-01,  3.7848e-01,  5.6406e-01,\n",
       "          3.3422e-02,  6.7292e-01, -3.1006e-01, -3.1857e-01],\n",
       "        [-2.5449e-01, -3.1740e-01, -9.9386e-01,  5.0107e-01, -4.4340e-01,\n",
       "         -5.8743e-01,  8.8600e-01,  1.6617e-01, -1.0030e+00, -2.6448e-01,\n",
       "          5.7384e-01, -1.6106e-02, -6.6187e-01,  1.2011e+00, -1.0080e+00,\n",
       "          2.4273e-01,  1.0083e+00,  3.5950e-01, -6.2053e-01, -3.7367e-01,\n",
       "         -3.4416e-02, -1.4618e-03, -4.8162e-01,  1.6023e-01,  9.2560e-01,\n",
       "         -1.6729e-01,  1.9251e-01,  5.9714e-01, -9.3618e-02,  6.7007e-01,\n",
       "          8.2698e-01, -3.0080e-01,  8.2482e-01, -1.2337e-01,  4.5360e-01,\n",
       "         -7.9673e-01,  1.1773e+00, -4.5055e-01, -3.7368e-01,  5.1265e-01,\n",
       "         -4.8400e-01,  1.9496e-01,  9.5542e-01,  2.7571e-01, -5.9057e-01,\n",
       "          1.3672e-01,  1.2132e+00,  2.7603e-02, -9.9557e-02, -5.2732e-02,\n",
       "         -2.2574e-01,  5.1720e-01,  4.0437e-02, -8.5489e-01, -5.1998e-01,\n",
       "         -2.2305e-01, -7.0584e-01,  3.5501e-03,  2.9596e-01,  4.5525e-01,\n",
       "         -1.0517e+00,  4.0692e-01,  8.3007e-01, -5.6910e-01],\n",
       "        [ 2.7333e-01,  1.9264e-01,  4.7614e-01, -9.3989e-02,  3.1909e-01,\n",
       "          2.2900e-01,  8.7985e-01,  4.9615e-01, -2.2829e-01, -4.2981e-01,\n",
       "          8.5222e-01, -8.2663e-01, -3.2883e-01,  5.5912e-01, -1.0695e+00,\n",
       "          2.7982e-02,  1.9106e-01,  3.3043e-01, -2.0267e-01,  4.5361e-01,\n",
       "         -5.8682e-01,  6.6566e-01, -1.3712e-01, -9.9012e-01, -6.2805e-01,\n",
       "         -3.1932e-01,  1.4818e-01, -3.1065e-01,  3.2675e-01, -2.2709e-02,\n",
       "         -7.6655e-01, -7.3060e-02, -9.5697e-02,  7.0866e-01,  4.6969e-01,\n",
       "          9.0346e-02,  8.2249e-01, -9.6802e-02, -3.9903e-01, -2.4076e-01,\n",
       "         -4.9456e-01, -3.0519e-01, -7.1340e-03, -2.1230e-01,  7.6552e-01,\n",
       "         -2.4952e-01,  9.2186e-01,  2.7638e-02, -6.3935e-02,  3.2038e-01,\n",
       "          1.9383e-01,  2.0602e-01, -3.2343e-01,  7.1657e-02, -3.8374e-01,\n",
       "          5.5367e-01, -5.0381e-01,  7.3973e-01, -1.1036e+00, -3.4427e-01,\n",
       "          2.1595e-01, -1.9270e-01,  7.3756e-01, -2.8007e-01],\n",
       "        [ 4.6231e-01, -1.0137e-01,  7.0741e-01,  3.6664e-01,  1.0574e+00,\n",
       "          1.2157e+00, -2.7881e-01, -1.5748e+00,  8.0073e-01, -3.5928e-01,\n",
       "         -1.0711e+00,  1.5008e-01,  4.7492e-01,  1.5155e-01, -1.9703e-01,\n",
       "          9.4312e-02, -3.6484e-01,  8.6140e-01,  7.7031e-01, -6.0599e-02,\n",
       "          6.9405e-01,  6.8031e-01,  1.5179e-01, -8.1890e-02, -5.7672e-01,\n",
       "          9.0702e-01, -5.1446e-01,  5.7745e-01,  7.6351e-01, -1.0425e+00,\n",
       "         -4.1444e-01, -1.2375e+00, -6.3587e-01,  9.4468e-01,  4.4115e-01,\n",
       "         -1.2409e-01, -1.0443e+00,  1.6172e-02, -6.3531e-02, -7.4732e-01,\n",
       "         -6.4687e-01, -1.2192e-03, -5.4826e-01,  5.9099e-01,  1.2119e+00,\n",
       "         -6.9665e-01, -6.9102e-02, -6.9630e-01, -5.8015e-01,  6.1095e-01,\n",
       "          2.7442e-01, -1.3859e-01,  3.6437e-01, -3.8400e-02,  6.5800e-01,\n",
       "         -2.7799e-01, -7.6366e-01, -3.8073e-01, -3.4188e-02, -1.5617e+00,\n",
       "          3.5124e-01, -1.2134e-01,  4.5078e-01, -3.2120e-01],\n",
       "        [ 4.1411e-01,  3.0828e-01, -1.7487e-01, -4.4209e-01, -9.7102e-01,\n",
       "         -1.1624e-02,  1.9887e-02, -1.9441e-01, -6.7467e-01, -3.0505e-01,\n",
       "         -4.4636e-01,  8.8879e-01, -2.1934e-02,  4.2338e-01,  9.3157e-02,\n",
       "         -6.3342e-01, -1.7873e-01, -3.7975e-01, -5.9702e-02, -4.7209e-01,\n",
       "         -3.9552e-01,  2.6267e-01,  9.4446e-01, -5.3652e-01, -2.7399e-01,\n",
       "          4.5868e-01,  1.0569e-01,  6.3851e-01,  1.0003e-01, -2.5316e-01,\n",
       "         -2.2023e-01, -7.2337e-01, -3.5884e-01,  2.7130e-01, -9.6566e-01,\n",
       "          3.4442e-01,  2.1835e-01,  9.1512e-01,  6.6898e-01, -1.0890e+00,\n",
       "          7.8850e-01,  1.4992e-01, -1.4300e-01, -2.1502e-01, -2.4637e-02,\n",
       "          1.8933e-01,  3.4320e-02, -2.8123e-01,  5.7167e-02,  4.4389e-01,\n",
       "          1.5086e-01,  2.3074e-01, -6.8656e-01, -2.3945e-01,  4.4778e-01,\n",
       "         -1.3552e-01,  7.2626e-01, -3.3581e-01, -7.1165e-01, -6.0915e-01,\n",
       "         -1.0548e-01, -5.0057e-01,  6.2025e-01, -2.6093e-01],\n",
       "        [ 5.6152e-01,  4.0249e-01,  5.5856e-02,  2.1659e-01,  6.2452e-01,\n",
       "          1.2412e+00, -1.1872e-01, -3.5306e-01, -3.9699e-01, -8.4904e-01,\n",
       "          3.7164e-02,  3.1927e-01,  3.0506e-01, -8.2239e-01,  9.4211e-01,\n",
       "          4.8076e-01,  1.4884e+00,  2.6561e-01,  1.5667e-01, -8.7357e-01,\n",
       "          2.3377e-01,  6.1494e-01, -1.1639e-01,  3.0526e-01, -1.1177e-01,\n",
       "         -6.8553e-02,  1.7826e-01, -3.1279e-01, -1.0531e-01, -7.0239e-01,\n",
       "         -3.3840e-01,  3.3229e-02, -4.2618e-01,  6.2915e-01, -1.0338e-01,\n",
       "          8.1901e-01, -1.0713e+00,  1.6104e-01, -2.7673e-01, -1.0176e+00,\n",
       "          5.1285e-01,  1.6993e-01,  6.2420e-02, -5.4973e-01, -7.2731e-01,\n",
       "         -2.6512e-01,  5.9619e-01,  8.6111e-01,  3.2217e-01,  9.0783e-01,\n",
       "         -1.3377e-01,  1.5766e-01,  2.6258e-01,  5.1516e-01,  3.4336e-01,\n",
       "          7.2334e-01,  1.4164e-01,  7.7078e-02, -3.2411e-01,  5.3812e-01,\n",
       "         -5.7164e-01, -3.8126e-01, -1.1371e-01,  6.4948e-02]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_packed.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a4ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_packed.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90946613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
