{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ba8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mamba_ssm import Mamba2\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# need to be careful with setting d_model, headdim, and expand\n",
    "# packing had a ton of issues with casual conv1d when trying to use\n",
    "# arbitrary settings for these parameters.\n",
    "# what I know is that d_model = 64, headdim = 4, expand = 2 works\n",
    "# seems to suggest that https://github.com/state-spaces/mamba/issues/351\n",
    "# we need (d_model * expand) / headdim to be multiple of 8, that is\n",
    "# `(d_model * expand) / headdim % 8`\n",
    "# doing a bit of testing, it seems that is not the case? it is just that\n",
    "# some combinations result in lower level errors for some f#%$#@ reason\n",
    "# ok, never mind, it seems to be the case that for normal batched inputs,\n",
    "# just about any combination works, but for packed inputs where we \n",
    "# specify the seq_lens, some combinations lead to the causal-conv1d\n",
    "# thinking that the shape of the input (in terms of channels being last)\n",
    "# is not correct. It seems it does seem to  be the case that the rule\n",
    "# of (d_model * expand) / headdim % 8 == 0 holds for packed inputs.\n",
    "batch, length, dim = 2, 16, 96\n",
    "expand = 2\n",
    "headdim = 4\n",
    "if not (dim * expand / headdim) % 8 == 0:\n",
    "    print(\"d_model * expand must be multiple of headdim * 8\")\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "model = Mamba2(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    headdim=headdim,\n",
    "    d_state=16,  # SSM state expansion factor\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=expand,    # Block expansion factor\n",
    ")\n",
    "opt = AdamW(model.parameters(), lr=1e-3)\n",
    "model = model.to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70d9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = y.mean()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29749fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afd79e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 comparison: True\n",
      "y2 comparison: True\n"
     ]
    }
   ],
   "source": [
    "# Let's test packed sequences\n",
    "# Create two tensors of different lengths\n",
    "s1 = 3\n",
    "s2 = 3\n",
    "x1 = torch.randn(1, s1, dim).to(\"cuda\")\n",
    "x2 = torch.randn(1, s2, dim).to(\"cuda\")\n",
    "\n",
    "seq_idx = [0] * s1 + [1] * s2\n",
    "seq_idx = torch.tensor(seq_idx, device=\"cuda\", dtype=torch.int32).unsqueeze(0)\n",
    "\n",
    "# Get individual outputs\n",
    "with torch.no_grad():\n",
    "    y1_individual = model(x1)\n",
    "    y2_individual = model(x2)\n",
    "\n",
    "# Create packed input\n",
    "x_packed = torch.cat([x1, x2], dim=1)\n",
    "x_packed.requires_grad_(True)\n",
    "cu_seqlens = torch.tensor([0, s1, s1 + s2], dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# Get packed output\n",
    "with torch.no_grad():\n",
    "    #y_packed = model(x_packed, seq_idx=seq_idx, cu_seqlens=cu_seqlens).squeeze(0)\n",
    "    y_packed = model(x_packed, seq_idx=seq_idx).squeeze(0)\n",
    "\n",
    "# Split packed output\n",
    "y1_packed = y_packed[:s1].unsqueeze(0)\n",
    "y2_packed = y_packed[s1:].unsqueeze(0)\n",
    "\n",
    "# Check if the outputs are the same\n",
    "print(\"y1 comparison:\", torch.allclose(y1_individual, y1_packed, atol=1e-6))\n",
    "print(\"y2 comparison:\", torch.allclose(y2_individual, y2_packed, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c167e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.2116e-01,  2.4107e-01, -1.5129e+00,  3.8587e-01, -5.8004e-01,\n",
       "         -1.6634e-01, -1.3824e+00,  4.4393e-01, -2.9099e-02,  7.7948e-01,\n",
       "         -6.6768e-01, -1.0424e+00, -2.0781e-01,  2.0198e-01, -7.2246e-01,\n",
       "          4.3984e-01,  6.4999e-01,  3.1778e-01,  2.6821e-01,  5.1650e-01,\n",
       "          6.3873e-01, -1.6768e-01,  4.0387e-01, -2.9645e-01,  7.3715e-02,\n",
       "          5.7566e-01,  5.1389e-01,  8.0220e-01,  1.2376e+00,  7.9729e-02,\n",
       "         -8.4012e-01,  1.2893e-01, -2.7089e-01, -5.3847e-01,  1.0451e-01,\n",
       "         -2.4162e-01, -1.5693e-02,  1.8588e-01,  6.6236e-01, -7.4285e-01,\n",
       "          1.2007e+00, -6.3125e-01,  3.2688e-01,  3.3484e-01, -7.5681e-02,\n",
       "         -1.9244e-02, -6.3390e-01, -9.8153e-01,  5.6085e-01,  3.7954e-01,\n",
       "          3.0841e-01,  9.4786e-01,  3.1047e-01,  1.0744e+00,  8.5448e-01,\n",
       "         -1.2287e-01, -4.8137e-02,  2.0482e-01,  7.8514e-01, -6.4747e-01,\n",
       "         -4.9899e-06, -5.4974e-01, -1.2144e-01, -1.9491e-02, -2.0232e-01,\n",
       "         -1.0877e+00, -3.2753e-01, -2.9335e-01,  1.0593e-01,  7.8858e-01,\n",
       "          5.4389e-01,  1.2753e+00,  2.4510e-01, -1.4593e-02,  5.5040e-02,\n",
       "         -3.4343e-02, -4.9689e-01,  1.7332e-01, -4.4902e-01,  7.2100e-01,\n",
       "         -7.8358e-01,  5.2380e-01,  3.4754e-01, -1.2038e-02, -2.8840e-01,\n",
       "         -3.3443e-01, -5.3579e-03,  7.1514e-01, -1.3782e-01, -3.6215e-01,\n",
       "         -3.2043e-01, -6.8356e-01, -6.5427e-02, -1.9331e-01,  3.6725e-01,\n",
       "         -3.4422e-01],\n",
       "        [ 2.1131e-01, -9.7920e-01,  2.2477e-01, -4.2464e-01,  8.9552e-01,\n",
       "         -5.1403e-01,  7.8362e-01,  7.0197e-01, -6.1669e-01, -4.5118e-01,\n",
       "         -1.1395e+00, -9.0635e-01, -7.4918e-01,  8.1676e-01,  8.9323e-02,\n",
       "          2.6600e-01, -1.1128e-01, -7.2633e-02,  2.4113e-01,  6.1053e-01,\n",
       "         -5.5288e-01,  7.6842e-01, -5.1836e-01,  6.6108e-01, -1.1802e+00,\n",
       "         -2.5157e-01,  7.5022e-01,  3.7452e-01,  3.4528e-01,  1.1612e-01,\n",
       "          4.2787e-01,  2.1473e-01, -5.8783e-01,  5.9834e-01,  1.0347e+00,\n",
       "         -5.3177e-01,  6.4680e-01,  2.8348e-01,  2.2116e-01,  4.6768e-01,\n",
       "          4.1865e-02, -5.8228e-01,  9.8234e-01, -3.9777e-01, -6.7168e-01,\n",
       "         -1.7272e-01, -3.2194e-01, -9.5808e-01,  5.0286e-01,  2.7143e-01,\n",
       "         -7.2005e-01, -1.7766e-01,  1.4570e+00, -4.4370e-01, -4.9969e-01,\n",
       "         -4.4205e-01,  2.3274e-01,  4.0099e-01, -2.8841e-01, -3.5889e-01,\n",
       "          6.6825e-01,  8.4556e-01,  3.2816e-01, -4.4289e-01, -5.2770e-01,\n",
       "         -1.7812e-01,  6.2215e-01,  1.7861e-02,  4.8791e-01,  2.4599e-01,\n",
       "          4.3182e-01, -6.6554e-01, -1.5007e-01,  3.5782e-01, -9.2439e-02,\n",
       "         -3.0291e-01, -4.7086e-01,  3.3178e-02, -4.1284e-01,  7.7050e-01,\n",
       "          5.0979e-01, -1.3397e-01,  2.4457e-01,  3.8847e-01,  5.1821e-01,\n",
       "         -1.1624e-01,  7.5066e-01, -2.8244e-01, -4.7132e-01,  6.0238e-01,\n",
       "         -2.7411e-01,  7.4545e-02,  8.1175e-01, -5.9546e-02,  3.8290e-01,\n",
       "         -5.3991e-01],\n",
       "        [-9.1968e-01,  4.8944e-01,  7.6623e-02,  1.3042e+00, -1.1027e+00,\n",
       "          3.0576e-01, -7.8547e-01, -3.6920e-01,  7.3963e-01,  9.2838e-01,\n",
       "          3.9546e-01,  2.5730e-01,  6.2931e-02,  3.2350e-01, -1.0122e-01,\n",
       "         -1.1807e-02,  6.0228e-02,  1.1187e+00, -2.4519e-01,  1.2433e-01,\n",
       "          9.8014e-01,  6.9576e-01, -5.6096e-02,  1.4485e-01, -2.8487e-01,\n",
       "         -6.0915e-02, -3.5862e-01,  5.1528e-01,  3.2880e-01, -7.1026e-01,\n",
       "          1.8950e-01,  6.7859e-01, -2.9153e-01, -9.2561e-01,  2.6200e-01,\n",
       "          7.5880e-02,  4.7145e-01, -5.7137e-01,  3.3810e-02,  5.4249e-01,\n",
       "          8.9307e-01, -5.1714e-01,  3.9343e-02, -4.9601e-01, -1.0470e+00,\n",
       "          8.9691e-02,  8.4585e-01,  6.1948e-01, -4.4002e-01,  9.9373e-01,\n",
       "          2.2993e-01,  8.9345e-02,  1.1105e+00, -4.0182e-01,  4.8725e-01,\n",
       "         -3.7222e-01, -1.0790e+00, -7.6413e-01, -2.8483e-01,  1.0570e+00,\n",
       "         -9.7599e-01, -4.4267e-01,  4.8514e-01,  5.3090e-01, -2.7624e-01,\n",
       "          1.4849e-01, -6.8926e-01,  5.7604e-01,  7.2135e-01,  1.3227e-01,\n",
       "          5.5729e-01, -2.4525e-01,  7.2288e-01,  3.9564e-02, -2.2405e-01,\n",
       "         -1.6114e-02, -1.3503e-01,  1.1222e+00,  8.0615e-01,  6.1092e-01,\n",
       "         -4.7217e-01, -4.1249e-01,  5.3020e-01,  5.9766e-02, -1.6440e-01,\n",
       "          2.4519e-01,  1.0912e+00,  2.4317e-01, -7.5117e-02,  4.6101e-01,\n",
       "         -1.6182e-01, -1.0095e+00, -5.5407e-01, -5.5430e-01, -4.8916e-01,\n",
       "          8.3108e-01],\n",
       "        [ 2.5296e-01,  5.9914e-01,  2.8556e-01,  7.8547e-01, -4.0636e-01,\n",
       "         -4.0381e-01, -6.3671e-01,  7.0074e-02,  7.3016e-01, -1.6571e-01,\n",
       "          1.1156e-01, -3.5792e-01, -2.5114e-01,  8.8094e-02, -4.3471e-01,\n",
       "         -5.7404e-02,  1.2504e+00,  3.9063e-01, -6.0316e-01, -7.6570e-01,\n",
       "          2.2803e-01,  1.8039e-01, -1.0376e+00, -1.7188e-01,  3.6950e-01,\n",
       "         -7.2032e-01, -8.5295e-01,  1.8917e-01,  2.5386e-01, -1.0831e+00,\n",
       "         -2.5408e-01, -2.9696e-01,  1.0776e+00, -1.8840e-02, -1.0781e-01,\n",
       "          2.1123e-01,  4.0433e-01, -5.2703e-01,  1.9587e-01,  1.3764e-01,\n",
       "          7.0500e-01,  9.1726e-01, -7.4907e-02,  2.4502e-01, -7.1841e-01,\n",
       "          3.3337e-02,  1.4800e+00,  3.3162e-01, -4.5137e-01, -3.8354e-01,\n",
       "         -2.9861e-01,  3.7898e-01, -6.7907e-01,  3.0023e-01,  7.1332e-01,\n",
       "         -8.1292e-01, -5.1379e-03,  3.9350e-01, -3.4961e-01,  2.5657e-01,\n",
       "         -2.5949e-01, -3.9012e-01,  7.7005e-02, -1.7795e-01,  5.4344e-01,\n",
       "          7.8075e-01,  2.8808e-02,  5.2428e-01,  1.2251e-01, -5.5184e-01,\n",
       "         -6.2791e-01, -1.4107e-01,  4.7523e-01,  6.7499e-01, -3.7452e-01,\n",
       "         -7.3423e-02,  2.8950e-01,  7.0948e-01, -1.7874e-01, -1.1046e-01,\n",
       "          5.9505e-01, -6.4173e-02, -9.2472e-03, -7.7311e-01,  8.4085e-01,\n",
       "          7.6595e-02, -8.0106e-01, -4.1716e-02,  1.0285e+00,  2.4243e-01,\n",
       "          1.5592e-01, -1.4429e-01, -1.0564e+00, -1.4857e-01, -1.2269e+00,\n",
       "         -6.3795e-01],\n",
       "        [-3.3593e-01, -5.1477e-01, -3.8685e-01,  6.2675e-01, -6.3145e-01,\n",
       "          3.7459e-02, -7.3551e-01, -3.1452e-01,  2.4113e-01,  2.9244e-01,\n",
       "         -8.2329e-01,  2.8863e-01,  1.1359e-01, -3.1699e-01, -2.8418e-02,\n",
       "         -4.4648e-01,  3.6921e-01,  1.3703e+00, -2.8774e-01,  2.9223e-01,\n",
       "         -2.0012e-01,  3.2364e-01, -4.0230e-02, -1.0121e+00,  2.4949e-01,\n",
       "          7.2987e-01,  4.5192e-01,  7.2525e-01,  8.6010e-01,  4.8002e-02,\n",
       "         -9.0263e-01, -3.6511e-01, -2.5566e-01, -9.2117e-02, -1.2295e-01,\n",
       "         -8.0287e-02, -6.1292e-01,  2.4824e-01,  1.1605e+00,  3.4577e-01,\n",
       "          5.5650e-01, -1.0265e+00, -1.1448e+00, -6.3806e-01,  3.1093e-01,\n",
       "         -5.3284e-01,  3.4306e-01,  3.7169e-01, -1.2691e-01, -9.6538e-02,\n",
       "          7.2845e-01,  7.8783e-01, -1.1666e-01,  1.8676e-01, -7.4946e-02,\n",
       "         -3.8639e-01,  6.8680e-02, -3.8037e-02,  3.8604e-01,  3.9763e-03,\n",
       "         -1.7637e-01, -8.9766e-01,  1.1437e-01,  6.3688e-01, -2.6920e-01,\n",
       "         -3.1984e-01, -2.2346e-01,  6.7957e-02, -2.7237e-03, -8.4195e-01,\n",
       "          1.5108e-02, -2.9007e-02,  5.6484e-01,  5.9108e-02, -3.4076e-01,\n",
       "         -6.5031e-01, -3.1098e-01,  3.0100e-01,  4.8620e-01, -3.7192e-01,\n",
       "          2.8727e-01, -3.5172e-01,  4.1962e-01,  8.2503e-02,  3.9528e-02,\n",
       "         -9.8627e-02, -5.2764e-01,  8.9731e-01, -2.1891e-01, -6.8130e-01,\n",
       "         -1.2566e-03, -1.2712e+00, -4.3679e-01, -5.2192e-01, -5.7923e-01,\n",
       "          1.5006e-01],\n",
       "        [-3.7993e-01,  1.0567e+00, -7.0953e-01, -1.0658e-02, -5.1190e-01,\n",
       "          8.4967e-01, -9.6430e-01, -3.9768e-01, -3.0689e-03, -3.8301e-01,\n",
       "          7.9541e-01,  5.1549e-01, -4.1608e-02, -5.7847e-01,  7.7390e-01,\n",
       "          4.1591e-01,  6.5977e-01, -7.8991e-01, -1.3840e+00, -4.5926e-01,\n",
       "         -4.6704e-01, -7.9792e-01,  1.9951e-01, -7.1264e-02, -8.0109e-01,\n",
       "          6.2683e-02,  4.8400e-02,  1.3825e+00,  4.7011e-01, -2.4830e-01,\n",
       "         -8.9246e-01,  1.3436e+00, -1.2544e+00, -6.1171e-01,  3.8812e-01,\n",
       "         -7.4592e-01,  1.5125e-02,  7.4107e-02, -8.5436e-01,  7.5462e-02,\n",
       "         -2.0800e-01, -4.8447e-01,  4.4273e-01,  1.8304e-01,  4.7632e-01,\n",
       "         -2.3492e-01, -2.0245e-01, -5.3618e-01,  5.0718e-01, -1.1479e-01,\n",
       "         -5.0948e-01,  8.9492e-01, -5.8844e-01, -8.3056e-01, -9.7996e-02,\n",
       "          1.6876e-01, -5.8708e-01, -8.3235e-01,  5.1431e-03,  4.7500e-01,\n",
       "          2.9295e-01,  8.2833e-01,  2.2703e-01,  4.6963e-01,  2.8010e-01,\n",
       "         -2.3178e-01, -5.0873e-01, -2.3378e-01,  8.4324e-01,  7.0343e-01,\n",
       "          9.1951e-02, -5.7880e-01, -4.4078e-01,  3.5939e-01,  1.0614e-01,\n",
       "         -3.3646e-01, -7.0703e-01,  8.8286e-01,  2.3489e-01,  3.0625e-01,\n",
       "         -1.5302e+00, -3.0506e-02, -4.0155e-01,  2.9824e-01, -4.3628e-01,\n",
       "          8.5125e-04,  2.6750e-01,  9.2403e-01,  4.0873e-01, -7.3244e-01,\n",
       "         -7.4957e-01, -1.0640e+00, -7.1222e-01,  2.8309e-01, -3.1316e-01,\n",
       "          7.8005e-01]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_packed.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07a4ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_packed.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90946613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
