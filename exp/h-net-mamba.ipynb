{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026ba8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mamba_ssm import Mamba2\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# need to be careful with setting d_model, headdim, and expand\n",
    "# packing had a ton of issues with casual conv1d when trying to use\n",
    "# arbitrary settings for these parameters.\n",
    "# what I know is that d_model = 64, headdim = 4, expand = 2 works\n",
    "# seems to suggest that https://github.com/state-spaces/mamba/issues/351\n",
    "# we need (d_model * expand) / headdim to be multiple of 8, that is\n",
    "# `(d_model * expand) / headdim % 8`\n",
    "batch, length, dim = 2, 16, 64\n",
    "expand = 2\n",
    "headdim = 4\n",
    "assert (dim * expand) % (headdim * 8) == 0, \"d_model * expand must be multiple of headdim * 8\"\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "model = Mamba2(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    headdim=4,\n",
    "    d_state=16,  # SSM state expansion factor\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    ")\n",
    "opt = AdamW(model.parameters(), lr=1e-3)\n",
    "model = model.to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70d9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = y.mean()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29749fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd79e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 comparison: True\n",
      "y2 comparison: True\n"
     ]
    }
   ],
   "source": [
    "# Let's test packed sequences\n",
    "# Create two tensors of different lengths\n",
    "s1 = 3\n",
    "s2 = 3\n",
    "x1 = torch.randn(1, s1, dim).to(\"cuda\")\n",
    "x2 = torch.randn(1, s2, dim).to(\"cuda\")\n",
    "\n",
    "seq_idx = [0] * s1 + [1] * s2\n",
    "seq_idx = torch.tensor(seq_idx, device=\"cuda\", dtype=torch.int32).unsqueeze(0)\n",
    "\n",
    "# Get individual outputs\n",
    "with torch.no_grad():\n",
    "    y1_individual = model(x1)\n",
    "    y2_individual = model(x2)\n",
    "\n",
    "# Create packed input\n",
    "x_packed = torch.cat([x1, x2], dim=1)\n",
    "cu_seqlens = torch.tensor([0, s1, s1 + s2], dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# Get packed output\n",
    "with torch.no_grad():\n",
    "    #y_packed = model(x_packed, seq_idx=seq_idx, cu_seqlens=cu_seqlens).squeeze(0)\n",
    "    y_packed = model(x_packed, seq_idx=seq_idx).squeeze(0)\n",
    "\n",
    "# Split packed output\n",
    "y1_packed = y_packed[:s1].unsqueeze(0)\n",
    "y2_packed = y_packed[s1:].unsqueeze(0)\n",
    "\n",
    "# Check if the outputs are the same\n",
    "print(\"y1 comparison:\", torch.allclose(y1_individual, y1_packed, atol=1e-6))\n",
    "print(\"y2 comparison:\", torch.allclose(y2_individual, y2_packed, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c167e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
