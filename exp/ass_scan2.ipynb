{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ba6b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from assoc_scan import AssocScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b8a4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ass_scan = AssocScan(use_accelerated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "efa47bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "027c750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, s, d = 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33efda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((b,s,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0756c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, 0] = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c25e4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [ 4.3091e-01, -1.0117e+00, -4.8157e-01]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff3ff8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gates = torch.tensor([1,0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97cd8560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "         [ 4.3091e-01, -1.0117e+00, -4.8157e-01]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass_scan(gates, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c5a9365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "30006884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbad15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_p = pad(p, (1, 0), value = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cbbedeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = torch.ones(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b11351d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = torch.randn((1, s, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a73f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7049c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_keys = repeat(pl, 'd -> b 1 d', b = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50b9de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = torch.cat([start_keys, keys], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f88ecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000],\n",
       "         [-0.1717, -0.0144,  0.2643],\n",
       "         [ 0.2310, -0.8723, -1.3921]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "57030d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[:, pad_p == 1] = pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f7be3e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000],\n",
       "         [-0.1717, -0.0144,  0.2643],\n",
       "         [ 1.0000,  1.0000,  1.0000]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "95eccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = torch.tensor([[\n",
    "         [ 6.6796e-04,  1.0707e-02], # keep\n",
    "         [ 1.2260e+00, -1.0057e+00], # keep\n",
    "         [ 2.7146e-01, -5.9301e-01], # discard\n",
    "         [ 6.6796e-04,  1.0707e-02], # keep\n",
    "         [-4.1065e-01,  6.2196e-01]  # keep\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2e32ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b64e414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pad(m, (0, 1), value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "977dfb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.6796e-04,  1.0707e-02],\n",
       "         [ 1.2260e+00, -1.0057e+00],\n",
       "         [ 6.6796e-04,  1.0707e-02],\n",
       "         [-4.1065e-01,  6.2196e-01]]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = keys[:, m2 != 1]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary probs: tensor([[5.5319e-01, 9.9487e-01],\n",
    "        [1.0878e-05, 8.9463e-01],\n",
    "        [1.3683e-01, 5.5906e-01]], grad_fn=<ToPaddedTensorBackward0>)\n",
    "downsampled tokens: tensor([[[ 3.3987e-01,  4.6595e-01,  1.8461e-01,  1.2003e+00,  1.7549e-01,\n",
    "           4.0810e-01],\n",
    "         [-4.3039e-02,  1.5487e+00, -4.2201e-01, -7.4840e-01,  4.9490e-01,\n",
    "           1.1368e-01]],\n",
    "\n",
    "        [[-1.6289e-05,  1.3337e-06,  5.0730e-06,  9.9005e-07,  1.3297e-05,\n",
    "          -1.0687e-05],\n",
    "         [-1.4945e+00, -1.2153e+00, -1.4739e-01, -4.3173e-01,  7.0506e-02,\n",
    "          -4.7886e-02]],\n",
    "\n",
    "        [[-6.9309e-02,  1.1804e-01,  3.3555e-02,  1.2978e-01,  4.7402e-02,\n",
    "          -1.8877e-01],\n",
    "         [ 8.7156e-01,  2.0464e-01, -2.8968e-01,  2.4440e-01,  7.3751e-01,\n",
    "          -3.2294e-01]]], grad_fn=<MulBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
