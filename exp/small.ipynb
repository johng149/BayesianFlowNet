{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "32400f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def doc_ids_to_cu_seqlen(doc_ids: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Convert document IDs to cumulative sequence lengths for use in attention mechanisms.\n",
    "\n",
    "    Args:\n",
    "        doc_ids (Tensor): A tensor of shape (batch_size, seq_len) containing document IDs.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: A 1D tensor of cumulative sequence lengths.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = doc_ids.shape\n",
    "    # Find where groups change\n",
    "    is_new_group = torch.cat(\n",
    "        [\n",
    "            torch.ones_like(doc_ids[:, :1], dtype=torch.bool),\n",
    "            doc_ids[:, 1:] != doc_ids[:, :-1],\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    # Get the indices where new groups start\n",
    "    group_start_indices = torch.where(is_new_group)[1]\n",
    "    return torch.cat(\n",
    "        [group_start_indices, torch.tensor([seq_len], device=doc_ids.device)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "02f48a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def normalize_output(q: torch.Tensor, k: torch.Tensor, o: torch.Tensor) -> torch.Tensor:\n",
    "    k = k.cumsum(1)\n",
    "    z = (q * k).sum(-1, keepdim=True)\n",
    "    return o / (z + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cf3af095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from fla.ops.simple_gla import chunk_simple_gla\n",
    "\n",
    "\n",
    "@torch.compiler.disable\n",
    "def chunk_linear_attn(\n",
    "    q: torch.Tensor,\n",
    "    k: torch.Tensor,\n",
    "    v: torch.Tensor,\n",
    "    scale: float | None = None,\n",
    "    initial_state: torch.Tensor | None = None,\n",
    "    output_final_state: bool = False,\n",
    "    normalize: bool = True,\n",
    "    head_first: bool = False,\n",
    "    cu_seqlens: torch.Tensor | None = None,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        q (torch.Tensor):\n",
    "            queries of shape `[B, T, H, K]`.\n",
    "        k (torch.Tensor):\n",
    "            keys of shape `[B, T, H, K]`.\n",
    "        v (torch.Tensor):\n",
    "            values of shape `[B, T, H, V]`.\n",
    "        scale (Optional[float]):\n",
    "            Scale factor for the linear attention scores.\n",
    "            If not provided, it will default to `1 / sqrt(K)`. Default: `None`.\n",
    "        initial_state (Optional[torch.Tensor]):\n",
    "            Initial state of shape `[B, H, K, V]`. Default: `None`.\n",
    "        output_final_state (Optional[bool]):\n",
    "            Whether to output the final state of shape `[B, H, K, V]`. Default: `False`.\n",
    "        normalize (bool):\n",
    "            Whether to normalize the output. Default: `True`.\n",
    "        head_first (Optional[bool]):\n",
    "            Whether the inputs are in the head-first format. Default: `False`.\n",
    "            This argument has been deprecated.\n",
    "\n",
    "    Returns:\n",
    "        o (torch.Tensor):\n",
    "            Outputs of shape `[B, T, H, V]`.\n",
    "        final_state (torch.Tensor):\n",
    "            Final state of shape `[B, H, K, V]` if `output_final_state=True` else `None`.\n",
    "    \"\"\"\n",
    "\n",
    "    if head_first:\n",
    "        raise DeprecationWarning(\n",
    "            \"head_first is deprecated and will be removed in a future version. \"\n",
    "            \"Please use head_first=False for now instead.\",\n",
    "        )\n",
    "    if not head_first:\n",
    "        if q.shape[1] < q.shape[2]:\n",
    "            raise DeprecationWarning(\n",
    "                f\"Input tensor shape suggests potential format mismatch: seq_len ({q.shape[1]}) < num_heads ({q.shape[2]}). \"\n",
    "                \"This may indicate the inputs were passed in head-first format [B, H, T, ...] \"\n",
    "                \"when head_first=False was specified. \"\n",
    "                \"Please verify your input tensor format matches the expected shape [B, T, H, ...].\",\n",
    "            )\n",
    "    if scale is None:\n",
    "        scale = k.shape[-1] ** -0.5\n",
    "    o, final_state = chunk_simple_gla(\n",
    "        q=q,\n",
    "        k=k,\n",
    "        v=v,\n",
    "        scale=scale,\n",
    "        initial_state=initial_state,\n",
    "        output_final_state=output_final_state,\n",
    "        cu_seqlens=cu_seqlens,\n",
    "    )\n",
    "    if normalize:\n",
    "        o = normalize_output(q * scale, k, o)\n",
    "    return o, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023-2025, Songlin Yang, Yu Zhang\n",
    "\n",
    "\"\"\"\n",
    "https://github.com/corl-team/rebased/blob/main/flash_linear_attention/fla/layers/rebased_fast.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "from fla.modules.feature_map import RebasedFeatureMap\n",
    "from fla.ops.linear_attn import fused_chunk_linear_attn\n",
    "from fla.ops.rebased import parallel_rebased\n",
    "\n",
    "\n",
    "class ReBasedLinearAttention(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int,\n",
    "        l_max: int = 2048,\n",
    "        feature_dim: int = 16,\n",
    "        num_key_value_heads: int = 16,\n",
    "        num_heads: int = 16,\n",
    "        use_gamma: bool | None = True,\n",
    "        use_beta: bool | None = True,\n",
    "        normalize: bool | None = True,\n",
    "        causal: bool = True,\n",
    "        eps: float = 1e-5,\n",
    "        mode: str = \"parallel\",\n",
    "        layer_idx: int | None = None,\n",
    "        **kwargs,\n",
    "    ) -> ReBasedLinearAttention:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.l_max = l_max\n",
    "        self.mode = mode\n",
    "        assert self.mode in [\"fused_chunk\", \"parallel\", 'chunk']\n",
    "\n",
    "        self.feature_dim = feature_dim\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = self.hidden_size // self.num_key_value_heads\n",
    "        self.use_gamma = use_gamma\n",
    "        self.use_beta = use_beta\n",
    "        self.normalize = normalize\n",
    "        self.causal = causal\n",
    "        self.eps = eps\n",
    "        self.mode = mode\n",
    "        self.layer_idx = layer_idx\n",
    "\n",
    "        self.feature_map = RebasedFeatureMap(self.feature_dim, use_gamma, use_beta, normalize)\n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.feature_dim * self.num_heads, bias=False)\n",
    "        self.k_proj = nn.Linear(self.hidden_size, self.feature_dim * self.num_heads, bias=False)\n",
    "        self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=False)\n",
    "        self.dropout = nn.Identity()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, **kwargs):\n",
    "        mode = self.mode\n",
    "        q = rearrange(\n",
    "            self.q_proj(hidden_states),\n",
    "            \"... (h d) -> ... h d\",\n",
    "            h=self.num_heads,\n",
    "            d=self.feature_dim,\n",
    "        )\n",
    "        k = rearrange(\n",
    "            self.k_proj(hidden_states),\n",
    "            \"... (h d) -> ... h d\",\n",
    "            h=self.num_heads,\n",
    "            d=self.feature_dim,\n",
    "        )\n",
    "        v = rearrange(\n",
    "            self.v_proj(hidden_states),\n",
    "            \"... (h d) -> ... h d\",\n",
    "            h=self.num_key_value_heads,\n",
    "            d=self.head_dim,\n",
    "        )\n",
    "        cu_seqlens = kwargs.get(\"cu_seqlens\", None)\n",
    "        q, k = self.feature_map(q, flatten=(mode != 'parallel')), self.feature_map(k, flatten=(mode != 'parallel'))\n",
    "        if mode == \"fused_chunk\":\n",
    "            o,_ = fused_chunk_linear_attn(\n",
    "                q=q,\n",
    "                k=k,\n",
    "                v=v,\n",
    "                normalize=True,\n",
    "                scale=1,\n",
    "                cu_seqlens=cu_seqlens,\n",
    "            )\n",
    "        elif mode == 'chunk':\n",
    "            o,_ = chunk_linear_attn(\n",
    "                q=q,\n",
    "                k=k,\n",
    "                v=v,\n",
    "                normalize=True,\n",
    "                scale=1,\n",
    "                cu_seqlens=cu_seqlens,\n",
    "            )\n",
    "        elif mode == 'parallel':\n",
    "            assert q.shape[-1] <= 128\n",
    "            o = parallel_rebased(\n",
    "                q=q,\n",
    "                k=k,\n",
    "                v=v,\n",
    "                eps=self.eps,\n",
    "                use_scale=True,\n",
    "                use_normalize=True,\n",
    "            )\n",
    "        o = rearrange(o, \"... h d -> ... (h d)\")\n",
    "        o = self.o_proj(o)\n",
    "        o = self.dropout(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "60633253",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 16\n",
    "s2 = 18\n",
    "b,s,d = 1,s1+s2,512\n",
    "num_heads = 8\n",
    "mode = \"chunk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2752f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebased = ReBasedLinearAttention(\n",
    "    hidden_size=d,\n",
    "    num_heads=num_heads,\n",
    "    mode=mode,\n",
    "    num_key_value_heads=num_heads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de8487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(b,s,d)\n",
    "doc_ids = []\n",
    "index = 0\n",
    "for seq_len in [s1, s2]:\n",
    "    doc_ids.extend([index] * seq_len)\n",
    "    index += 1\n",
    "doc_ids = torch.tensor([doc_ids])\n",
    "cu_seqlens = doc_ids_to_cu_seqlen(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7115d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, :s1, :] = -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa53fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebased = rebased.cuda()\n",
    "x = x.cuda()\n",
    "cu_seqlens = cu_seqlens.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9da08240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 16, 34], device='cuda:0')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu_seqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7d5b7613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1044: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "out = rebased(x, cu_seqlens=cu_seqlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f0ceb6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 34, 512])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "18ea7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d3f87910",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = x[:, :s1, :]\n",
    "second = x[:, s1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ce883744",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_out = rebased(first)\n",
    "second_out = rebased(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "475526e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.6224e+08,  3.7914e+08,  4.8357e+08,  ...,  1.5805e+07,\n",
       "            2.0560e+08, -5.6705e+08],\n",
       "          [ 1.6224e+08,  3.7914e+08,  4.8357e+08,  ...,  1.5805e+07,\n",
       "            2.0560e+08, -5.6705e+08],\n",
       "          [ 1.6223e+08,  3.7915e+08,  4.8359e+08,  ...,  1.5810e+07,\n",
       "            2.0562e+08, -5.6707e+08],\n",
       "          ...,\n",
       "          [ 1.6220e+08,  3.7928e+08,  4.8374e+08,  ...,  1.5856e+07,\n",
       "            2.0574e+08, -5.6723e+08],\n",
       "          [ 1.6219e+08,  3.7928e+08,  4.8374e+08,  ...,  1.5856e+07,\n",
       "            2.0574e+08, -5.6723e+08],\n",
       "          [ 1.6222e+08,  3.7921e+08,  4.8366e+08,  ...,  1.5830e+07,\n",
       "            2.0567e+08, -5.6714e+08]]], device='cuda:0',\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([[[-0.1034, -0.5111, -0.2731,  ...,  0.0754,  0.0731,  0.2537],\n",
       "          [ 0.0235,  0.1614, -0.2155,  ..., -0.0512, -0.1835,  0.3704],\n",
       "          [ 0.0539, -0.0804, -0.2118,  ...,  0.0968, -0.0406,  0.4769],\n",
       "          ...,\n",
       "          [-0.0614,  0.1224, -0.2283,  ...,  0.2209, -0.0005,  0.0989],\n",
       "          [-0.1197, -0.1598, -0.0908,  ...,  0.0907,  0.0805,  0.1453],\n",
       "          [ 0.0604, -0.1067, -0.0495,  ..., -0.0554,  0.0077, -0.0444]]],\n",
       "        device='cuda:0', grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_out, second_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c97090a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.6224e+08,  3.7914e+08,  4.8357e+08,  ...,  1.5805e+07,\n",
       "            2.0560e+08, -5.6705e+08],\n",
       "          [ 1.6224e+08,  3.7914e+08,  4.8357e+08,  ...,  1.5805e+07,\n",
       "            2.0560e+08, -5.6705e+08],\n",
       "          [ 1.6223e+08,  3.7915e+08,  4.8359e+08,  ...,  1.5810e+07,\n",
       "            2.0562e+08, -5.6707e+08],\n",
       "          ...,\n",
       "          [ 1.6220e+08,  3.7928e+08,  4.8374e+08,  ...,  1.5856e+07,\n",
       "            2.0574e+08, -5.6723e+08],\n",
       "          [ 1.6219e+08,  3.7928e+08,  4.8374e+08,  ...,  1.5856e+07,\n",
       "            2.0574e+08, -5.6723e+08],\n",
       "          [ 1.6222e+08,  3.7921e+08,  4.8366e+08,  ...,  1.5830e+07,\n",
       "            2.0567e+08, -5.6714e+08]]], device='cuda:0',\n",
       "        grad_fn=<SliceBackward0>),\n",
       " tensor([[[-0.2436, -0.3086, -0.0769,  ...,  0.0433,  0.1269,  0.2462],\n",
       "          [-0.1647,  0.0130, -0.0547,  ..., -0.1089, -0.0193,  0.1714],\n",
       "          [-0.0200,  0.0212, -0.0332,  ..., -0.0176,  0.0199,  0.1294],\n",
       "          ...,\n",
       "          [-0.0648,  0.0329, -0.0858,  ...,  0.0747, -0.0277,  0.0703],\n",
       "          [-0.1185, -0.0420, -0.0471,  ..., -0.0037,  0.0232,  0.0222],\n",
       "          [ 0.0157, -0.0483, -0.0475,  ...,  0.0094, -0.0333, -0.0686]]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, :s1, :], out[:, s1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "592553d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(first_out, out[:, :s1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3932da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(second_out, out[:, s1:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95cdd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't match but it doesn't carry information over either apparently\n",
    "# as setting the first half to -1e9 seems to have no effect on the second half output. Maybe this is fine???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
