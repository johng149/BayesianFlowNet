{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8pM05Qyk0IYu",
        "g2KB6jRB0Ta7",
        "z7VFJr2V0hRO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfbpnj8oYALn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.distributions.categorical import Categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discrete Case"
      ],
      "metadata": {
        "id": "5AQqWCBiZGMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants\n",
        "$t \\in \\mathbb{R}$ - timestep for denoising process in the range [0.0, 1.0]\n",
        "\n",
        "$n \\in \\mathbb{N}^+$ - total number of denoising steps\n",
        "\n",
        "$i \\in \\mathbb{N}^+$ such that $i \\leq n$ - current denoising step\n",
        "\n",
        "$\\beta(t)$ - accuracy at time $t$\n",
        "\n",
        "$\\beta(1)$ - we adjust this to define maximum possible accuracy\n",
        "\n",
        "$K$ - number of classes in our discrete distribution\n",
        "\n",
        "$x$ - ground truth\n",
        "\n",
        "$y'$ - noisy ground truth\n",
        "\n",
        "$\\delta_x$ - Kronocker delta of $x$ also known as the one-hot encoding\n",
        "\n",
        "$\\theta = \\text{softmax}(y')$ - input parameters to the network (scaled to be between -1 and 1 using $\\theta * 2 - 1$)"
      ],
      "metadata": {
        "id": "c2Xs1PbDYG0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "\n",
        "Suppose our ground truth $x$ is $[0, 1, 0]$, then $\\delta_x$ would be $[0, 1, 0]$\n",
        "\n",
        "$\\text{beta} = \\beta(1) * t^2$\n",
        "\n",
        "Normally $y' \\sim ùí©(\\text{beta} * (K * \\delta_x - 1), beta * K)$ but we do reparameterization to get:\n",
        "\n",
        "$y' = \\text{beta} * (K * \\delta_x - 1) + beta * K * \\epsilon$ where $\\epsilon$ is noise drawn from normal distribution with variance 1 and mean 0"
      ],
      "metadata": {
        "id": "l3oHZ3HLZxVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discrete simple example\n",
        "\n",
        "Suppose no batch dimension and ground truth is [0, 1, 0], at first denoising step (in other words, $t$ should be equal to 0)"
      ],
      "metadata": {
        "id": "-gCPMO5-banY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "i = 1\n",
        "beta1 = 4\n",
        "x = torch.tensor([0,1,0])\n",
        "delta_x = x\n",
        "K = len(x)"
      ],
      "metadata": {
        "id": "zlQhEAxwYHYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = (i - 1) / n"
      ],
      "metadata": {
        "id": "2an0kCcAZUXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = beta1 * (t**2)"
      ],
      "metadata": {
        "id": "7_0LR3-IZXBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = torch.normal(0, 1, size=delta_x.shape)"
      ],
      "metadata": {
        "id": "0IjXFbh6ZbNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime_left_term = beta * (K * delta_x - 1)\n",
        "y_prime_right_term = beta * K * epsilon"
      ],
      "metadata": {
        "id": "K2ohDSTNbs-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime = y_prime_left_term + y_prime_right_term"
      ],
      "metadata": {
        "id": "VSCfvqB6b3af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = F.softmax(y_prime, dim=-1)"
      ],
      "metadata": {
        "id": "JOugZqBOb99A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta # as expected, it is uniform distribution, as when t = 0, prior is completely uninformative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PZVusZ5cWJd",
        "outputId": "f013b710-d378-4d7b-d955-d9f7c2d8e7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3333, 0.3333, 0.3333])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled = 2 * theta - 1"
      ],
      "metadata": {
        "id": "TTehP2VScaf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FLqA2rvcg3V",
        "outputId": "071c615a-dd6d-46ad-e60e-b389c82c1805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3333, -0.3333, -0.3333])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discrete simple example\n",
        "\n",
        "Suppose no batch dimension and ground truth is [0, 1, 0], at middle of denoising step (in other words, $t$ should be equal to 0.5 or so)"
      ],
      "metadata": {
        "id": "P-Sj7FaRcvcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "i = 5\n",
        "beta1 = 4\n",
        "x = torch.tensor([0,1,0])\n",
        "delta_x = x\n",
        "K = len(x)"
      ],
      "metadata": {
        "id": "czWDTURjcvcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = (i - 1) / n"
      ],
      "metadata": {
        "id": "77B-JbBrcvcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = beta1 * (t**2)"
      ],
      "metadata": {
        "id": "RKkWtDUvcvcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = torch.normal(0, 1, size=delta_x.shape)"
      ],
      "metadata": {
        "id": "M5MqjWBLcvcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime_left_term = beta * (K * delta_x - 1)\n",
        "y_prime_right_term = beta * K * epsilon"
      ],
      "metadata": {
        "id": "yPcnkcNpcvcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime = y_prime_left_term + y_prime_right_term"
      ],
      "metadata": {
        "id": "uprn2ZvqcvcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = F.softmax(y_prime, dim=-1)"
      ],
      "metadata": {
        "id": "HSc4sEQYcvcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta # as expected, close to middle of denoising, data is somewhat informative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15e73b0-7301-4c6b-8249-16ff15d32781",
        "id": "TNInG4T1cvcY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0922, 0.0198, 0.8880])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled = 2 * theta - 1"
      ],
      "metadata": {
        "id": "LCefLIAvcvcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364de7e0-0060-478e-9365-0b9ee5d8fd32",
        "id": "xWfWiX-gcvcY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8156, -0.9603,  0.7759])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discrete simple example\n",
        "\n",
        "Suppose no batch dimension and ground truth is [0, 1, 0], at last denoising step (in other words, $t$ should be close to 1)"
      ],
      "metadata": {
        "id": "v-1T9Mz0c9Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "i = 10\n",
        "beta1 = 4\n",
        "x = torch.tensor([0,1,0])\n",
        "delta_x = x\n",
        "K = len(x)"
      ],
      "metadata": {
        "id": "ixbUiK7Ac9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = (i - 1) / n"
      ],
      "metadata": {
        "id": "3adV0tIWc9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = beta1 * (t**2)"
      ],
      "metadata": {
        "id": "WLT28MwDc9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = torch.normal(0, 1, size=delta_x.shape)"
      ],
      "metadata": {
        "id": "I80IwghDc9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime_left_term = beta * (K * delta_x - 1)\n",
        "y_prime_right_term = beta * K * epsilon"
      ],
      "metadata": {
        "id": "AwdU6U32c9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime = y_prime_left_term + y_prime_right_term"
      ],
      "metadata": {
        "id": "N3g-ANaqc9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = F.softmax(y_prime, dim=-1)"
      ],
      "metadata": {
        "id": "jn2XZdY5c9St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta # as expected, it is almost exactly equal to ground truth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8462abb0-09b3-425d-f444-27c8ef17bcfa",
        "id": "VHqWJdRJc9St"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.7434e-08, 2.6485e-03, 9.9735e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled = 2 * theta - 1"
      ],
      "metadata": {
        "id": "hCVgjZEGc9St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62e3b32-e2b5-43b5-ea72-95f5f0a7fd58",
        "id": "O0VZqQS1c9St"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0000, -0.9947,  0.9947])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuous Case"
      ],
      "metadata": {
        "id": "23e4zM0AtOKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants\n",
        "\n",
        "$\\sigma_1$ - the variance of the noise as $t \\to 1$\n",
        "\n",
        "$\\gamma(t) = 1 - \\sigma_1^{2t}$"
      ],
      "metadata": {
        "id": "7m0_bRVitRed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes\n",
        "\n",
        "The noise $\\mu$ is drawn from $ùí©(\\gamma(t) \\cdot x, \\gamma(t)(1 - \\gamma(t)))$"
      ],
      "metadata": {
        "id": "WLREgOUKuEDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous simple example\n",
        "\n",
        "Suppose no batch dimension, ground truth is $[0.2, 0.8, 0.1, 0.9]$, and $t = 0$"
      ],
      "metadata": {
        "id": "8pM05Qyk0IYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.2, 0.8, 0.1, 0.9])\n",
        "t = 0\n",
        "sigma_1 = 0.001"
      ],
      "metadata": {
        "id": "FScVKsRZchwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1 - sigma_1 ** (2 * t)"
      ],
      "metadata": {
        "id": "5K7T_F2iudVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = gamma * x\n",
        "variance = gamma * (1 - gamma)\n",
        "epsilon = torch.normal(0, 1, size=x.shape)"
      ],
      "metadata": {
        "id": "ySF6Q7QNzz9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, variance, epsilon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyrMfw9S0A_-",
        "outputId": "0e85386e-2ec0-467a-af7f-479107dd0b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0.]), 0.0, tensor([ 0.5200,  0.1092, -0.6988, -0.4410]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "jXyCM7780Dgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJvRbVrb0FYe",
        "outputId": "3bc326ba-8582-4a1a-cb41-07aaea994cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous simple example\n",
        "\n",
        "Suppose no batch dimension, ground truth is $[0.2, 0.8, 0.1, 0.9]$, and $t = 0.5$"
      ],
      "metadata": {
        "id": "g2KB6jRB0Ta7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.2, 0.8, 0.1, 0.9])\n",
        "t = 0.5\n",
        "sigma_1 = 0.001"
      ],
      "metadata": {
        "id": "w5gR7XFh0Ta8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1 - sigma_1 ** (2 * t)"
      ],
      "metadata": {
        "id": "6pHQNFLX0Ta8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = gamma * x\n",
        "variance = gamma * (1 - gamma)\n",
        "epsilon = torch.normal(0, 1, size=x.shape)"
      ],
      "metadata": {
        "id": "iIu00pBu0Ta8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, variance, epsilon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc95bcb1-f6be-43b6-92ad-b36f65dda602",
        "id": "a1lTRGIg0Ta9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1998, 0.7992, 0.0999, 0.8991]),\n",
              " 0.000999000000000001,\n",
              " tensor([ 1.6145,  0.4570, -0.4408, -1.7838]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "8HBXlEBo0Ta9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7425e324-6f63-40ff-d492-0c2c1aca6de6",
        "id": "H6MYWPdL0Ta9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2014, 0.7997, 0.0995, 0.8973])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous simple example\n",
        "\n",
        "Suppose no batch dimension, ground truth is $[0.2, 0.8, 0.1, 0.9]$, and $t = 1$"
      ],
      "metadata": {
        "id": "QEZ8vEIm0Yep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.2, 0.8, 0.1, 0.9])\n",
        "t = 1\n",
        "sigma_1 = 0.001"
      ],
      "metadata": {
        "id": "1L5DnzM60Yeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1 - sigma_1 ** (2 * t)"
      ],
      "metadata": {
        "id": "PG7eKSNj0Yeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = gamma * x\n",
        "variance = gamma * (1 - gamma)\n",
        "epsilon = torch.normal(0, 1, size=x.shape)"
      ],
      "metadata": {
        "id": "GA-ZJ8l70Yeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, variance, epsilon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a9ebc0-1a7f-4bc3-8c65-b43df48d2007",
        "id": "j2NKf3ae0Yeq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.2000, 0.8000, 0.1000, 0.9000]),\n",
              " 9.999990000287556e-07,\n",
              " tensor([-0.3440, -0.1561,  0.3768, -0.0716]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "NLSAi9RP0Yeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d20bacf-bdaf-4ff6-f3fb-e73d2998717e",
        "id": "xNa6Aij40Yer"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2000, 0.8000, 0.1000, 0.9000])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discrete Loss"
      ],
      "metadata": {
        "id": "z7VFJr2V0hRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discrete Loss example\n",
        "\n",
        "Suppose ground truth is $x = [0, 1, 0]$ (this means $K = 3$), $\\beta(1) = 4$. With $t$ drawn uniformly from range $[0, 1]$, suppose we get $t = 0.5$\n",
        "\n",
        "Recall that $\\beta(t) = t^2 \\cdot \\beta(1)$\n",
        "\n",
        "The input $y'$ is drawn from $ùí©(\\beta(t) \\cdot ( K \\cdot x - 1), \\beta(t) \\cdot K)$\n",
        "\n",
        "Then we have $\\theta = \\text{softmax}(y')$ and then $\\theta$ is scaled so values are between $-1$ and $1$ before being passed into the model.\n",
        "\n",
        "Suppose model output is $\\omega = [0.2, 0.6, 0.2]$\n",
        "\n",
        "The loss is:\n",
        "\n",
        "$K \\cdot \\beta(1) \\cdot t \\cdot || x - \\omega||^2$"
      ],
      "metadata": {
        "id": "fsvpZEno0my5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta_1 = 4\n",
        "x = torch.tensor([0, 1, 0])\n",
        "t = 0.5\n",
        "K = len(x)"
      ],
      "metadata": {
        "id": "psWEQdzv0bBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = beta_1 * (t**2)"
      ],
      "metadata": {
        "id": "O5oX0sKM2cij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = beta * K * x - 1"
      ],
      "metadata": {
        "id": "iN93XxIc2eZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variance = beta * K"
      ],
      "metadata": {
        "id": "5oKXW4fQ2h8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = torch.normal(0, 1, x.shape)"
      ],
      "metadata": {
        "id": "hmoI60Fu2iMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, variance, epsilon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2_ank-g22eF",
        "outputId": "4771d2d5-6dc0-47bc-925d-f584656662d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-1.,  2., -1.]), 3.0, tensor([ 0.6564, -0.1692, -0.8507]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "qwXHgXV8236e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc34e91M26jy",
        "outputId": "aa60cafe-9cd1-4270-e097-0c5e044d7259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.9691,  1.4925, -3.5521])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta = F.softmax(y_prime, dim=-1)"
      ],
      "metadata": {
        "id": "Iruoe40Z3P7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1oiVOxS3R_D",
        "outputId": "357583a0-1cab-4792-d8b9-4b823d61871f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3706, 0.6254, 0.0040])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta = theta * 2 - 1"
      ],
      "metadata": {
        "id": "E-JGFdE53Sdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta # we pass this into model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urBWsOXe3Uu5",
        "outputId": "e960dc49-6466-4ff5-e0ce-1d058e92131c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2589,  0.2508, -0.9919])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = torch.tensor([0.2, 0.6, 0.2])"
      ],
      "metadata": {
        "id": "K4ACwtiQ3VFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = K * beta_1 * t * torch.sum((x - model_output)**2)"
      ],
      "metadata": {
        "id": "x5VdFcbW3suh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ECpq9k53zfT",
        "outputId": "8a1955dd-b1b7-41cd-cd87-c508d828cd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4400)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continuous Loss"
      ],
      "metadata": {
        "id": "uYzntsuIi6es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continous Loss example\n",
        "\n",
        "Recall that $\\sigma_1$ is the variance the noise approaches as $t \\to 1$\n",
        "\n",
        "$\\gamma(t) = 1 - \\sigma_1^{2t}$\n",
        "\n",
        "The noise $\\mu$ is drawn from $ùí©(\\gamma(t) \\cdot x, \\gamma(t)(1 - \\gamma(t)))$\n",
        "\n",
        "We want the ground truth $x$, however, what the model produces is not the prediction of the ground truth $x'$ directly. Instead, the model predicts the noise $\\epsilon'$ that was added to the input, as a result of the reparameterization trick.\n",
        "\n",
        "$\\mu = \\gamma(t) \\cdot x + (\\sqrt{\\gamma(t) \\cdot (1-\\gamma(t))} \\cdot \\epsilon)$\n",
        "\n",
        "We can rearrange this equation to produce the model's effective prediction of $x'$ given its output $\\epsilon'$ like so:\n",
        "\n",
        "$x' = \\frac{\\mu}{\\gamma(t)} - (\\sqrt{ \\frac{1 - \\gamma(t)}{\\gamma(t)}} \\cdot \\epsilon')$\n",
        "\n",
        "The loss function is then $-\\ln(\\sigma_1) \\cdot \\mathbb{E}[\\frac{||x - x'||}{\\sigma_1^{2t}}]$\n",
        "\n",
        "There is an expectation term because we usually have batches. But if there is no batch dimension the expectation term goes away and we are left with its body."
      ],
      "metadata": {
        "id": "se3cvSIdi9Ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continous Loss simple example\n",
        "\n",
        "Let $\\sigma_1 = 0.001$, $t = 0.5$, and ground truth $x$ be $[0.3, 0.5, 0.2]$\n",
        "\n",
        "Suppose in response to $\\mu$ the model outputs $[0.05, -0.02, 0.03] = \\epsilon'$"
      ],
      "metadata": {
        "id": "C-ZkEspDuEUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_1 = 0.001\n",
        "t = 0.5\n",
        "gamma_t = 1 - sigma_1 ** (2 * t)\n",
        "x = torch.tensor([0.3, 0.5, 0.2])"
      ],
      "metadata": {
        "id": "sFP3YqyG35gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = gamma_t * x\n",
        "variance = gamma_t * (1 - gamma_t)\n",
        "epsilon = torch.normal(0, 1, x.shape)"
      ],
      "metadata": {
        "id": "2w9HMoD-uVFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu = gamma_t * x + (variance ** 0.5) * epsilon"
      ],
      "metadata": {
        "id": "wtVVYAxYuuJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu # we feed this into model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-8c-ZfYvBEV",
        "outputId": "cda9b5e0-f5e6-4aa2-9792-e48134cb163c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2959, 0.4435, 0.2119])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose model output is [0.05, -0.02, 0.03]\n",
        "epsilon_prime = torch.tensor([0.05, -0.02, 0.03])"
      ],
      "metadata": {
        "id": "Z5Qg2s_evFQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_prime = (mu / gamma_t) - (((1 - gamma_t) / gamma_t) ** 0.5) * epsilon_prime"
      ],
      "metadata": {
        "id": "y262p4N2vYA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_prime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB4lWbhXvj_B",
        "outputId": "555754ce-a788-4a8c-ae25-8ef84bfb1c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2946, 0.4446, 0.2112])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = -np.log(sigma_1) * torch.sum((x - x_prime) ** 2) / (sigma_1 ** (2*t))"
      ],
      "metadata": {
        "id": "4b6fsl6tvka4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOXJHirzvqUP",
        "outputId": "478e3876-e945-4126-ae56-4235d1488458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(22.2665)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian update step\n",
        "\n",
        "Bayesian update steps occur only during inference, as during training we opt to mimic its behavior instead of spending time calculating each actual step to improve compute utilization"
      ],
      "metadata": {
        "id": "vPo5Mhx5tAZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discrete bayesian update step\n",
        "\n",
        "$\\beta(1)$ - the highest possible accuracy as $t \\to 1$\n",
        "\n",
        "$n$ - total number of inference steps\n",
        "\n",
        "$i$ - current step out of the $n$ steps\n",
        "\n",
        "$K$ - number of classes\n",
        "\n",
        "We calculate accuracy $\\alpha$ with:\n",
        "\n",
        "$\\alpha = \\frac{\\beta(1) \\cdot (2 \\cdot i - 1)}{n^2}$\n",
        "\n",
        "We feed in the $\\text{input}$ to the model and take the model output to create a categorical distribution from the output and sample the distribution. We turn the sample into a one-hot encoding $\\nabla$ and then create a noise distribution $y$.\n",
        "\n",
        "$y \\sim ùí©(\\alpha \\cdot (K \\cdot \\nabla - 1), \\alpha \\cdot K)$\n",
        "\n",
        "After sampling from $y$ we calculate:\n",
        "\n",
        "$e^y \\cdot \\text{input} = \\text{res}$\n",
        "\n",
        "We then normalize the result with $\\frac{\\text{res}}{\\text{sum}(\\text{res})}$\n",
        "\n",
        "This normalized result is the input to the next loop"
      ],
      "metadata": {
        "id": "XFCrFLXdtCMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discrete bayesian update step example\n",
        "\n",
        "Suppose no batch dimension (or rather, batch size of 1)\n",
        "\n",
        "Suppose $\\beta_1 = 4$, $n = 20$, $i = 10$, $\\text{input} = [0.3, 0.5, 0.2]$\n",
        "\n",
        "Suppose the model outputs $[1.0, -0.5, 0.2]$ and when we sample it we get output class 1, which is encoded in a one-hot vector as $[1, 0, 0]$"
      ],
      "metadata": {
        "id": "phdljdNzE883"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beta_1 = 4\n",
        "n = 20\n",
        "i = 10\n",
        "alpha = beta_1 * ((2 * i - 1) / (n**2))"
      ],
      "metadata": {
        "id": "AC6jRNUqv6nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = torch.tensor([0.3, 0.5, 0.2])\n",
        "K = len(model_input)\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "1VMKuYpNE5rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = torch.tensor([1.0, -0.5, 0.2])"
      ],
      "metadata": {
        "id": "9R75oiw1FWgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dist = Categorical(logits=model_output)"
      ],
      "metadata": {
        "id": "25OqGCvFFdrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_sampled = output_dist.sample((batch_size,))"
      ],
      "metadata": {
        "id": "FJTMzhrkF6eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_one_hot = torch.tensor([[1, 0, 0]]) # normally we would use `F.one_hot(output_sampled, K)`, but this is a hard-coded example"
      ],
      "metadata": {
        "id": "JpZHqXa0G6vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = alpha * (K * sampled_one_hot - 1)\n",
        "variance = alpha * K\n",
        "epsilon = torch.normal(0, 1, sampled_one_hot.shape)"
      ],
      "metadata": {
        "id": "hLZUJvhBHI3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "namv1Q-0Hgx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDy1XE4cHjXG",
        "outputId": "db2ac077-dab4-44f7-fa2b-f3a4dccb344c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6075, -0.5093,  0.0739]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = torch.exp(y) * model_input"
      ],
      "metadata": {
        "id": "eQWEvg94Hjoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib46j7wXHqCJ",
        "outputId": "17ca2f7e-a0b5-440c-b204-aeeeebef6bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5507, 0.3005, 0.2153]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = res / torch.sum(res)"
      ],
      "metadata": {
        "id": "v_rJyFy1HvfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res # used as the input to the model in next inference step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0JhbR7FHxNG",
        "outputId": "2419947b-0c84-4e18-c01a-c126123b34b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5164, 0.2817, 0.2019]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continuous bayesian update step\n",
        "\n",
        "Recall that $\\sigma_1$ is the variance the noise approaches as $t \\to 1$\n",
        "\n",
        "$\\gamma(t) = 1 - \\sigma_1^{2t}$\n",
        "\n",
        "The noise $\\mu$ is drawn from $ùí©(\\gamma(t) \\cdot x, \\gamma(t)(1 - \\gamma(t)))$ during training, but during inference, it comes from previous bayesian update step.\n",
        "\n",
        "We want the ground truth $x$, however, what the model produces is not the prediction of the ground truth $x'$ directly. Instead, the model predicts the noise $\\epsilon'$ that was added to the input, as a result of the reparameterization trick.\n",
        "\n",
        "$\\mu = \\gamma(t) \\cdot x + (\\sqrt{\\gamma(t) \\cdot (1-\\gamma(t))} \\cdot \\epsilon)$\n",
        "\n",
        "We can rearrange this equation to produce the model's effective prediction of $x'$ given its output $\\epsilon'$ like so:\n",
        "\n",
        "$x' = \\frac{\\mu}{\\gamma(t)} - (\\sqrt{ \\frac{1 - \\gamma(t)}{\\gamma(t)}} \\cdot \\epsilon')$\n",
        "\n",
        "Let $n$ be total number of inference steps and $i$ be current inference step. We start with precision $p$\n",
        "\n",
        "The accuracy $\\alpha$ is calculated using:\n",
        "\n",
        "$\\alpha = \\sigma_1^{\\frac{-2i}{n}} \\cdot (1 - \\sigma_1^{\\frac{2}{n}})$\n",
        "\n",
        "We construct the $y$ value from a distribution:\n",
        "\n",
        "$y \\sim ùí©(x', \\alpha^{-1})$\n",
        "\n",
        "The new precision $p'$ is $p' = p + \\alpha$\n",
        "\n",
        "The updated input becomes $\\mu' = \\frac{\\mu \\cdot p + y \\cdot \\alpha}{p'}$ and this is used in the next inference step"
      ],
      "metadata": {
        "id": "8eVI-JmkIgQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = torch.tensor([0.25, 0.55, 0.18])\n",
        "p = 3\n",
        "t = 0.49\n",
        "sigma_1 = 0.001\n",
        "n = 100\n",
        "i = 50"
      ],
      "metadata": {
        "id": "Eg0f-QU2Hxcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose we feed in mu and get epsilon', and the effective x' is [0.31, 0.48, 0.22]\n",
        "x_prime = torch.tensor([0.31, 0.48, 0.22])\n",
        "alpha = (sigma_1 ** (-2 * i / n)) * (1 - sigma_1**(2/n))"
      ],
      "metadata": {
        "id": "ebFAORzxMXkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEwcdsAjMoS7",
        "outputId": "031bc21d-e284-41c5-cfac-dc711b92e53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129.0364100439194"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = x_prime\n",
        "variance = alpha ** (-1)\n",
        "epsilon = torch.normal(0, 1, x_prime.shape)"
      ],
      "metadata": {
        "id": "NU6nokSvMorj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = mean + variance * epsilon"
      ],
      "metadata": {
        "id": "9q66ekJqMv70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4ASO9pMMxiZ",
        "outputId": "5ed5ea41-0b5b-498d-dec4-d7f67be8526c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3117, 0.4742, 0.2356])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_prime = p + alpha"
      ],
      "metadata": {
        "id": "JiEwOpknMxyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_prime = (mu * p + y * alpha) / p_prime"
      ],
      "metadata": {
        "id": "RV4jeG_fM1yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_prime"
      ],
      "metadata": {
        "id": "dI1yao5EM511",
        "outputId": "c0d4547b-c7e2-45a4-f009-548723328c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3103, 0.4759, 0.2344])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kS4engwBM6Va"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}