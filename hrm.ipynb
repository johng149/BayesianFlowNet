{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20f2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sched import scheduler\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator, DistributedDataParallelKwargs\n",
    "from torch.optim import AdamW as Opt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau as ReduceLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.datasets.dataset_helper import make_collate_fn\n",
    "from src.datasets.shakespeare.shakespeare import ShakespeareDataset as Ds\n",
    "from src.nn.discrete_model import DiscreteModel as Model\n",
    "from src.schedule.vanilla import VanillaScheduler as Scheduler\n",
    "from src.tokenizers.byte.byte import ByT5Tokenizer as Tk\n",
    "from src.training.train import TrainingContext as Context\n",
    "from src.training.train import train\n",
    "from src.checkpointing.checkpointing import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b903b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "accelerator = Accelerator(\n",
    "    log_with=\"tensorboard\", project_dir=\"./runs\", kwargs_handlers=[ddp_kwargs]\n",
    ")\n",
    "checkpoint_name = \"shakespeare_byt5_packed_ebt\"\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "batch_size = 256\n",
    "seq_len = 128\n",
    "min_t = 1e-8\n",
    "num_workers = 3\n",
    "hidden_size = 768\n",
    "layers = 6\n",
    "heads = 12\n",
    "tk = Tk()\n",
    "vocab_size = tk.vocab_size()\n",
    "scheduler = Scheduler(20.4054 / vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a825b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    max_seq_len=seq_len,\n",
    "    K=vocab_size,\n",
    "    hidden_dim=hidden_size,\n",
    "    num_heads=heads,\n",
    "    layers=layers,\n",
    "    dropout=0.1,\n",
    "    use_chunkers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70996e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, _ = load_checkpoint(model, None, None, accelerator, checkpoint_dir + f\"/{checkpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733070e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_data = torch.load(\"debug.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c607d069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
       "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]],\n",
       "        device='cuda:1'),\n",
       " 't': tensor([[1.0000e-05, 1.0000e-05, 1.0000e-05,  ..., 1.0000e-05, 1.0000e-05,\n",
       "          1.0000e-05]], device='cuda:1'),\n",
       " 'mask': tensor([[False, False, False,  ...,  True,  True,  True]], device='cuda:1'),\n",
       " 'doc_ids': tensor([[  0,   0,   0,  ..., 255, 255, 255]], device='cuda:1')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "368159a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, t, mask, doc_ids = debug_data[\"theta\"], debug_data[\"t\"], debug_data[\"mask\"], debug_data[\"doc_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c20f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta.to(accelerator.device)\n",
    "t = t.to(accelerator.device)\n",
    "mask = mask.to(accelerator.device)\n",
    "doc_ids = doc_ids.to(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8a0bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/john/Tertiary/Projects/ML/BayesianFlowNet/.venv/lib/python3.12/site-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  return _C._get_float32_matmul_precision()\n"
     ]
    }
   ],
   "source": [
    "logits, l = model(theta, t, mask, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea734b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesianflownet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
