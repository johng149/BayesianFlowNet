{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d93f3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.tokenizers.ascii.ascii_tokenizer import ASCIITokenizer as Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09830dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"debug_data_current_epoch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1573a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN found in output\n",
      "NaN found in formatted_loss\n",
      "NaN found in l_infty_loss\n",
      "NaN found in var_loss\n",
      "NaN found in div_loss\n",
      "NaN found in l\n",
      "Checking model state\n"
     ]
    }
   ],
   "source": [
    "data.keys() # dict_keys(['x', 't', 'output', 'alpha', 'formatted_loss', 'l_infty_loss', 'var_loss', 'div_loss', 'l', 'model_state_dict'])\n",
    "\n",
    "# check every value for NaNs\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor) and torch.isnan(value).any():\n",
    "        print(f\"NaN found in {key}\")\n",
    "    elif isinstance(value, dict):\n",
    "        print(\"Checking model state\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            if isinstance(sub_value, torch.Tensor) and torch.isnan(sub_value).any():\n",
    "                print(f\"NaN found in {key}.{sub_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f6045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 32\n",
    "tokenizer = Tokenizer()\n",
    "model_kwargs = {\n",
    "    \"max_seq_len\": max_seq_len,\n",
    "    \"K\": tokenizer.vocab_size(),\n",
    "    \"hidden_dim\": 512,\n",
    "    \"num_heads\": 8,\n",
    "    \"layers\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a7e5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nn.models.discrete_model import DiscreteModel\n",
    "\n",
    "model = DiscreteModel(**model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ececcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(data['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "417a6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t = data['x'].cpu(), data['t'].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d456e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f61d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
       " \n",
       "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan],\n",
       "          [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([-2.6785, -2.6811, -2.6812, -2.6811, -2.6804, -2.6795, -2.6793, -2.6800,\n",
       "         -2.6785, -2.6801, -2.6805, -2.6813, -2.6805, -2.6809, -2.6810, -2.6812,\n",
       "         -2.6785, -2.6812, -2.6796, -2.6796, -2.6811, -2.6789, -2.6795, -2.6813,\n",
       "         -2.6785, -2.6812, -2.6813, -2.6810, -2.6809, -2.6813, -2.6808, -2.6807,\n",
       "         -2.6785, -2.6786, -2.6809, -2.6799, -2.6813, -2.6812, -2.6809, -2.6786,\n",
       "         -2.6785, -2.6813, -2.6795, -2.6812, -2.6813, -2.6813, -2.6810, -2.6811,\n",
       "         -2.6785, -2.6791, -2.6794, -2.6811, -2.6813, -2.6799, -2.6810, -2.6812,\n",
       "         -2.6785, -2.6785, -2.6792, -2.6799, -2.6803, -2.6813, -2.6813, -2.6811],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beb0c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, alpha = model.beta_and_alpha(t, tokenizer.vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abfa4f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.6785e-06, -1.4770e+00, -1.5288e+00, -2.4835e+00, -8.8041e-01,\n",
       "         -4.0479e-01, -3.3264e-01, -6.1584e-01, -2.6785e-06, -7.0165e-01,\n",
       "         -9.4166e-01, -1.8685e+00, -9.3534e-01, -2.6451e+00, -2.5092e+00,\n",
       "         -1.6764e+00, -2.6785e-06, -2.2560e+00, -4.4587e-01, -4.6710e-01,\n",
       "         -1.3812e+00, -1.7136e-01, -4.2483e-01, -2.0943e+00, -2.6785e-06,\n",
       "         -2.1890e+00, -1.7288e+00, -1.2947e+00, -1.2306e+00, -2.1246e+00,\n",
       "         -1.1625e+00, -1.0675e+00, -2.6785e-06, -4.8445e-02, -2.6781e+00,\n",
       "         -5.6973e-01, -2.0704e+00, -2.2214e+00, -1.2079e+00, -5.0947e-02,\n",
       "         -2.6785e-06, -2.0688e+00, -4.2078e-01, -2.3500e+00, -1.8849e+00,\n",
       "         -1.8465e+00, -2.5623e+00, -1.4666e+00, -2.6785e-06, -2.4352e-01,\n",
       "         -3.6537e-01, -2.4676e+00, -1.7725e+00, -5.7731e-01, -2.5315e+00,\n",
       "         -2.2546e+00, -2.6785e-06, -2.8782e-03, -2.7426e-01, -5.9708e-01,\n",
       "         -8.2768e-01, -1.9792e+00, -2.0898e+00, -2.3763e+00],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([-2.6785, -2.6811, -2.6812, -2.6811, -2.6804, -2.6795, -2.6793, -2.6800,\n",
       "         -2.6785, -2.6801, -2.6805, -2.6813, -2.6805, -2.6809, -2.6810, -2.6812,\n",
       "         -2.6785, -2.6812, -2.6796, -2.6796, -2.6811, -2.6789, -2.6795, -2.6813,\n",
       "         -2.6785, -2.6812, -2.6813, -2.6810, -2.6809, -2.6813, -2.6808, -2.6807,\n",
       "         -2.6785, -2.6786, -2.6809, -2.6799, -2.6813, -2.6812, -2.6809, -2.6786,\n",
       "         -2.6785, -2.6813, -2.6795, -2.6812, -2.6813, -2.6813, -2.6810, -2.6811,\n",
       "         -2.6785, -2.6791, -2.6794, -2.6811, -2.6813, -2.6799, -2.6810, -2.6812,\n",
       "         -2.6785, -2.6785, -2.6792, -2.6799, -2.6803, -2.6813, -2.6813, -2.6811],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23d6e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.discrete_helper import theta, y_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd6b7b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_distribution(beta, tokenizer.vocab_size(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7769e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_v = beta.view(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e49b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = beta_v * (tokenizer.vocab_size() * x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9604c9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.6785e-06,  2.6785e-06,  2.6785e-06,  ...,  2.6785e-06,\n",
       "           2.6785e-06,  2.6785e-06],\n",
       "         [ 2.6785e-06, -9.9103e-05,  2.6785e-06,  ...,  2.6785e-06,\n",
       "           2.6785e-06,  2.6785e-06],\n",
       "         [ 2.6785e-06,  2.6785e-06,  2.6785e-06,  ...,  2.6785e-06,\n",
       "           2.6785e-06,  2.6785e-06],\n",
       "         ...,\n",
       "         [ 2.6785e-06,  2.6785e-06,  2.6785e-06,  ...,  2.6785e-06,\n",
       "          -9.9103e-05,  2.6785e-06],\n",
       "         [-9.9103e-05,  2.6785e-06,  2.6785e-06,  ...,  2.6785e-06,\n",
       "           2.6785e-06,  2.6785e-06],\n",
       "         [-9.9103e-05,  2.6785e-06,  2.6785e-06,  ...,  2.6785e-06,\n",
       "           2.6785e-06,  2.6785e-06]],\n",
       "\n",
       "        [[ 1.4770e+00,  1.4770e+00,  1.4770e+00,  ...,  1.4770e+00,\n",
       "           1.4770e+00,  1.4770e+00],\n",
       "         [ 1.4770e+00, -5.4647e+01,  1.4770e+00,  ...,  1.4770e+00,\n",
       "           1.4770e+00,  1.4770e+00],\n",
       "         [ 1.4770e+00,  1.4770e+00,  1.4770e+00,  ...,  1.4770e+00,\n",
       "           1.4770e+00,  1.4770e+00],\n",
       "         ...,\n",
       "         [ 1.4770e+00,  1.4770e+00,  1.4770e+00,  ...,  1.4770e+00,\n",
       "          -5.4647e+01,  1.4770e+00],\n",
       "         [-5.4647e+01,  1.4770e+00,  1.4770e+00,  ...,  1.4770e+00,\n",
       "           1.4770e+00,  1.4770e+00],\n",
       "         [-5.4647e+01,  1.4770e+00,  1.4770e+00,  ...,  1.4770e+00,\n",
       "           1.4770e+00,  1.4770e+00]],\n",
       "\n",
       "        [[ 1.5288e+00,  1.5288e+00,  1.5288e+00,  ...,  1.5288e+00,\n",
       "           1.5288e+00,  1.5288e+00],\n",
       "         [ 1.5288e+00, -5.6565e+01,  1.5288e+00,  ...,  1.5288e+00,\n",
       "           1.5288e+00,  1.5288e+00],\n",
       "         [ 1.5288e+00,  1.5288e+00,  1.5288e+00,  ...,  1.5288e+00,\n",
       "           1.5288e+00,  1.5288e+00],\n",
       "         ...,\n",
       "         [ 1.5288e+00,  1.5288e+00,  1.5288e+00,  ...,  1.5288e+00,\n",
       "          -5.6565e+01,  1.5288e+00],\n",
       "         [-5.6565e+01,  1.5288e+00,  1.5288e+00,  ...,  1.5288e+00,\n",
       "           1.5288e+00,  1.5288e+00],\n",
       "         [-5.6565e+01,  1.5288e+00,  1.5288e+00,  ...,  1.5288e+00,\n",
       "           1.5288e+00,  1.5288e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.9792e+00,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00],\n",
       "         [ 1.9792e+00,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00],\n",
       "         [ 1.9792e+00,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00],\n",
       "         ...,\n",
       "         [ 1.9792e+00,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00],\n",
       "         [ 1.9792e+00,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00],\n",
       "         [-7.3230e+01,  1.9792e+00,  1.9792e+00,  ...,  1.9792e+00,\n",
       "           1.9792e+00,  1.9792e+00]],\n",
       "\n",
       "        [[ 2.0898e+00,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00],\n",
       "         [ 2.0898e+00,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00],\n",
       "         [ 2.0898e+00,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00],\n",
       "         ...,\n",
       "         [ 2.0898e+00,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00],\n",
       "         [ 2.0898e+00,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00],\n",
       "         [-7.7323e+01,  2.0898e+00,  2.0898e+00,  ...,  2.0898e+00,\n",
       "           2.0898e+00,  2.0898e+00]],\n",
       "\n",
       "        [[ 2.3763e+00,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00],\n",
       "         [ 2.3763e+00,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00],\n",
       "         [ 2.3763e+00,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00],\n",
       "         ...,\n",
       "         [ 2.3763e+00,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00],\n",
       "         [ 2.3763e+00,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00],\n",
       "         [-8.7924e+01,  2.3763e+00,  2.3763e+00,  ...,  2.3763e+00,\n",
       "           2.3763e+00,  2.3763e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ed34e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = beta_v * tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "423cb423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0178e-04]],\n",
       "\n",
       "        [[-5.6124e+01]],\n",
       "\n",
       "        [[-5.8094e+01]],\n",
       "\n",
       "        [[-9.4372e+01]],\n",
       "\n",
       "        [[-3.3456e+01]],\n",
       "\n",
       "        [[-1.5382e+01]],\n",
       "\n",
       "        [[-1.2640e+01]],\n",
       "\n",
       "        [[-2.3402e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-2.6663e+01]],\n",
       "\n",
       "        [[-3.5783e+01]],\n",
       "\n",
       "        [[-7.1002e+01]],\n",
       "\n",
       "        [[-3.5543e+01]],\n",
       "\n",
       "        [[-1.0051e+02]],\n",
       "\n",
       "        [[-9.5348e+01]],\n",
       "\n",
       "        [[-6.3702e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-8.5728e+01]],\n",
       "\n",
       "        [[-1.6943e+01]],\n",
       "\n",
       "        [[-1.7750e+01]],\n",
       "\n",
       "        [[-5.2484e+01]],\n",
       "\n",
       "        [[-6.5118e+00]],\n",
       "\n",
       "        [[-1.6144e+01]],\n",
       "\n",
       "        [[-7.9583e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-8.3184e+01]],\n",
       "\n",
       "        [[-6.5695e+01]],\n",
       "\n",
       "        [[-4.9200e+01]],\n",
       "\n",
       "        [[-4.6761e+01]],\n",
       "\n",
       "        [[-8.0735e+01]],\n",
       "\n",
       "        [[-4.4174e+01]],\n",
       "\n",
       "        [[-4.0565e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-1.8409e+00]],\n",
       "\n",
       "        [[-1.0177e+02]],\n",
       "\n",
       "        [[-2.1650e+01]],\n",
       "\n",
       "        [[-7.8674e+01]],\n",
       "\n",
       "        [[-8.4413e+01]],\n",
       "\n",
       "        [[-4.5901e+01]],\n",
       "\n",
       "        [[-1.9360e+00]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-7.8614e+01]],\n",
       "\n",
       "        [[-1.5990e+01]],\n",
       "\n",
       "        [[-8.9299e+01]],\n",
       "\n",
       "        [[-7.1627e+01]],\n",
       "\n",
       "        [[-7.0169e+01]],\n",
       "\n",
       "        [[-9.7367e+01]],\n",
       "\n",
       "        [[-5.5731e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-9.2537e+00]],\n",
       "\n",
       "        [[-1.3884e+01]],\n",
       "\n",
       "        [[-9.3770e+01]],\n",
       "\n",
       "        [[-6.7355e+01]],\n",
       "\n",
       "        [[-2.1938e+01]],\n",
       "\n",
       "        [[-9.6198e+01]],\n",
       "\n",
       "        [[-8.5674e+01]],\n",
       "\n",
       "        [[-1.0178e-04]],\n",
       "\n",
       "        [[-1.0937e-01]],\n",
       "\n",
       "        [[-1.0422e+01]],\n",
       "\n",
       "        [[-2.2689e+01]],\n",
       "\n",
       "        [[-3.1452e+01]],\n",
       "\n",
       "        [[-7.5209e+01]],\n",
       "\n",
       "        [[-7.9413e+01]],\n",
       "\n",
       "        [[-9.0300e+01]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa656f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]],\n",
       "\n",
       "        [[nan]]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c7820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
